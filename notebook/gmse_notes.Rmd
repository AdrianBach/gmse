---
title: "Game-theoretic management strategy evaluation (G-MSE)"
author: "Brad Duthie"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: default
  pdf_document:
    fig_caption: yes
  word_document:
    fig_caption: yes
    pandoc_args:
    - --csl
    - evolution.csl
    reference_docx: docx_template.docx
header-includes:
- \usepackage{amsmath}
- \usepackage{natbib}
- \usepackage{lineno}
- \linenumbers
- \bibliographystyle{amnatnat}
linestretch: 1
csl: evolution.csl
bibliography: references.bib
---

```{r, echo=FALSE}
library(shiny)
library(rhandsontable)
```

********************************************************************************

> **This notebook tracks progress on the development of [G-MSE software](https://bradduthie.github.io/gmse/), for game-theoretic management strategy evaluation, and related issues surrounding the development and application of game theory for addressing questions of biodiversity and food security.**

********************************************************************************

<a name="contents">Contents:</a>
================================================================================

[Project updates](#updates)

 - **2017**

     - **FEB** [1](#u-1-FEB-2017)
     - **JAN** [31](#u-31-JAN-2017), [30](#u-30-JAN-2017), [29](#u-29-JAN-2017), [27](#u-27-JAN-2017), [26](#u-26-JAN-2017), [25](#u-25-JAN-2017), [24](#u-24-JAN-2017), [23](#u-23-JAN-2017), [22](#u-22-JAN-2017), [20](#u-20-JAN-2017), [19](#u-19-JAN-2017), [18](#u-18-JAN-2017), [17](#u-17-JAN-2017), [16](#u-16-JAN-2017), [15](#u-15-JAN-2017), [13](#u-13-JAN-2017), [11](#u-11-JAN-2017), [10](#u-10-JAN-2017)
 
 - **2016**

     - **DEC** [22](#u-22-DEC-2016)

[Towards a Game-theoretic Management Strategy Evaluation (G-MSE)](#intro)

[General model development](#gendev)

[General software development](#soft)

[Game-theory modelling (game.c; green box above)](#game)

[Game-theory and modelling](#gamemod)

[Notes regarding Nilsen's MSE](#Nilsen)

[Some side-notes that might be of use](#side)

[Potentially relevant conferences and workshops](#meetings)

[References consulted and annotated (Mendeley)](#ref)

[References cited](#cited)

********************************************************************************

<a name="updates">Project updates:</a>
================================================================================

> <a name="u-1-FEB-2017">Update: 1 FEB 2017</a>

**More thinking about agent fitness functions**

While I have a general idea of how to implement the genetic algorithm now, how agents make decisions and act on them is still not clear from a modelling perspective, so more critical thinking needs to be done here before any coding. Unlike the `resource` and `observation` models, I also think it might be better, given the complexity, to write a prototype of the code in R to show proof of concept before optimising the code in c. One thing that I think every agent needs will be some sort of *total budget* (note, this budget is not necessarily currency -- at the moment, I'm thinking about it more like a time budget; it's also possible we'll need two budgets, giving the option of one used explicitly for time and the other for currency, but I'm keeping it simple for now). This will give us the option of constraining agents' behaviours if desired so that agents cannot take unrealistic actions to increase their utility, and instead might have to consider trade-offs between different actions. For example, a farmer might be able to either tend crops, scare or kill organisms, build fence, or lobby the manager to increase utility, even though the *best* thing to do would be all four. A utility function would then determine how a combination of actions maps to utility, and a genetic algorithm could find the optimal behaviour to get the highest utility. We might consider different stake-holders, or different types of stake-holders, to have different total budgets from which to make decisions -- these budgets could also be affected by, and affect, `RESOURCES`. 

In the software, what this might look like is each `AGENT` having the opportunity to modify the following:

  - Other agents' *utility values* (lobbying)
  - Other agents' *actions* (harassment or intimidation)
  - Resource mortality (hunting)
  - Resource birth rate (castration)
  - Resource location (scaring)
  - Landscape movement ease (fencing)
  - Landscape productivity (farming)

Note that this way of conceptualising the implementation of actions is broad enough to include managers (who might lobby stake-holders, or intimidate them through laws to not do something). There might be other things to consider, but this suggests to me at least seven potential variables that an agent could affect, and agents will need to maximise their utility using a genetic algorithm that tweaks all of these parameter values -- ideally it would also take into account past actions of other agents to predict utility.

Agents might also be spatially restricted in their ability to perform any of these actions, thus making strategy dependent upon location (e.g., a farmer might not be able to hunt in certain areas). Here the option to define `type2` agents could come in hand -- one agent might be represented by multiple rows of the `AGENT` array with actions for each type `type2`, but each row having a unique `xloc` and `yloc`, thereby representing land owned. Managers could *own* all land, or just public land if they cannot do anything on stake-holder land. Some agents might have locations of -1 (or lower), meaning that they cannot do anything that requires control of land.

> <a name="u-31-JAN-2017">Update: 31 JAN 2017</a>

**Implementation of agent strategies**

More needs to be planned for the input and output of agent strategies. That is, what variables should and should not be available to managers and stake-holders when optimising strategies through the genetic algorithm, and how should these variables be incorporated into a strategy that causes agents to take one or more actions? Note, there are plenty of resourecs for incorporating multiple objectives into genetic algorithms [e.g., @Fonseca1998; @Fonseca1993; @ReyHorn1993; @Jaszkiewicz2002], so agents can be complex in their utility functions. What I'm talking more about is *what do agents get to consider when optimising to maximise their own utility functions*? And *what kinds of actions do stake-holders engage in upon formulating a strategy?* **Once the answers to these questions are clear, it will possible to start the process of coding `manager` and `user` functions**. Some potential things to consider as variables affecting manager and stake-holder strategies:

 - Observed density of resources produced by manager reports. This could as reported from the observation function (or as statistics from an analysis on these observations), or perhaps something directly from the `RESOURCE` array if resources are meant to be known (e.g., if hunting licenses or crop yields are modelled as resources). 
 - Direct knowledge of and interest in some spatially restricted area, perhaps representing a stake-holder's farm or other property -- or their common hunting grounds. Stake-holders utility functions might therefore be particularly affected by the *distribution* of resources and any management policy that explicitly considers geography. I've not seen models that do anything like this, but given the importance of local interests and therefore spatial dynamics in ConFooBio case studies, and in conservation more generally, I think spatial distribution needs to be included.
 - History of resource abundance distributions, perhaps placing diminishing weight on older resource abundances and distributions.
 - History of previous management policies and stake-holder actions.
 - Uncertainty associated with any of the previous bullet points.
 
Some things to consider as potential actions (outputs) of `manager` and `user` functions:

 - A general approach to management; i.e., will the manager allow users to hunt resources? Will they protect areas of landscape so that some resources cannot move into these areas? Will they cull resources themselves, or castrate them (`birth_rate = 0`), perhaps at some cost that should be considered explicitly? There are probably some high-level decisions to consider here, and it would be ideal to have many possibilities to choose from.
 - Will manager decisions be biased by resource age or type (e.g., sex), or by resource location? This could get very complex, but space is going to be important.
 - How are stake-holder agents going to respond to management decisions? Will they simply act to maximise their own utility within the rules set by management, or are these rules break-able if the cost to doing so is sufficiently low?
 - Can stake-holders 'lobby' managers, or other stake-holders, affecting their utility values and therefore their utility functions?
 - Are stake-holders limited by time or costs in some way? Should each be given some sort of budget (or should mangers?) that allows them to take certain actions, hence imposing a trade-off on things that they can do? Should this budget be affected by resources (e.g., crop yield)?

Neither of these lists are exhaustive, and the input and output options could get very complex. I think that this is okay as long as it doesn't cause the program to be too inefficient, intractable, or unrealistic. We want the options available to managers and stake-holders to reflect those of real systems as much as possible, but it is also worth thinking about whether some options can be safely pruned out of the software, or at least tabled for a later time.

**Note**, it *might* be that for most stake-holders, the strategy is really obvious -- always act in such a way as to maximise the resources that you're interested in -- no need to optimise much then because the action to take is clear. For managers, however, I can imagine that the decision will always be a bit more challenging, requiring trade-offs between the interests of different stake-holders in determining policy.

**Also Note**, there should be no need to tell managers what kind of approach to take with respect to policy (though this should be an option, of course). The genetic algorithm should be able to handle this sort of thing -- indeed, we might just see very different approaches come out of this model organically as a consequence of different resource abundances and distributions and stake-holder interactions. For example, between time steps, we might see managers switch from establishing a global hunting quota to prohibiting hunting and constructing fences (protected areas of landscape) instead; all we need to do is allow some sort of `switch` to affect manager's general approach, then incorporate this `switch` variable into the genetic algorithm.

**Use of genetic algorithms in ecology and evolution**

@Hamblin2013 has a nice methods paper on the use of genetic algorithms, focused especially on a ecology and evolution audience. He cites a highly relevant book by [Sean Luke](https://cs.gmu.edu/~sean/), which includes a general introduction to genetic algorithms, but also chapters on coevolution (competing strategies), multiobjective optimisation, and policy optimisation [@Luke2015]. @Luke2015 is particularly cited for the a quote on the utility of metaheuristics (which includes genetic algorithms), which I'll just include here in full:

> ''Metaheuristics are applied to I know it when I see it problems. They’re algorithms used to find answers to problems when you have very little to help you: you don’t know what the optimal solution looks like, you don’t know how to go about finding it in a principled way, you have very little heuristic information to go on, and brute-force search is out of the question because the space is too large. But if you're given a candidate solution to your problem, you can test it and assess how good it is. That is, you know a good one when you see it.''

I think this probably applies well to G-MSE. @Hamblin2013 notes that ''fitness evaluation'' is the larges performance bottelneck, so it is probably not worth investing too much energy on optimising the specifics of structure types, or crossover, mutation, and reproduction algorithms; instead, more attention might be paid to making speedy assessments of the fitness (payoffs) of agent strategies. It's also possible to control recombination (I'm going to call it that sometimes -- ''crossover'' strikes me as a bit of a confused term from the computer science literature) and mutation frequency through a parameter, so they could effectively be turned off if the parameter were set to zero. @Hamblin2013 notes that mutation *type* (e.g., random per locus or chromosome) is not terribly important (**but it's worth pointing out that the mutation rates from the literature search in Table 3 are generally much lower than @Luo2014 mentioned -- 0.1 still seems reasonable to me**), but **recombination parameters can be important -- one point crossover (i.e., forcing cross-over to happen once for all individuals) can break up good linkage combinations -- better to just use uniform (probabilistic) crossover.** Population sizes shown in Table 2 of @Hamblin2013 references shows that population sizes around 100-200 (though some much lower, but nearly always less than or equal to 2000) are common, with run lenghts commonly around 500 (1000 is also commmon); reals are about as common as binaries. The most popular selection algorithm is truncation, making up well over half of ecology and evolutionary biology applications of genetic algorithms [Table 1 of @Hamblin2013]. To my surprise, truncation selection is not the consensus recommendation for genetic algorithms (and proportional methods are quite bad when multiple strategies are near an optimum, resulting in premature convergence). The recommended selection method according to @Correia2010 is actually tournament selection. The algorithm is described by the quote below:

> ''It randomly picks *k* individuals from the population and copies the fittest of them to the mating pool. All the *k* individuals go back to the population. The process is repeated until the mating pool has the desired size.''

So tournament selection is not probabilistic -- in that sense, it is like truncated selection, but there is an extra sampling step that is iterated until the new generation is formed. If *k* is the same size as the mating pool, the this is effectively truncation selection, so really tournament selection is a generalisation of this that will be useful to code. @Hamblin2013 also cites a book chapter by [Syswerda](https://books.google.co.uk/books?hl=en&lr=&id=3TqeBQAAQBAJ&oi=fnd&pg=PA94&ots=Y499aq82nH&sig=n56XXHbYkA0vv4hRSfNfVk9ZDSs#v=onepage&q&f=false) (I'm still waiting on the full text, but the link has all of it) that shows that overlapping generations (termed ''steady state'' in the computer science literature) perform better than non-overlapping (termed ''generational'') algorithms. This can be easy to implement -- allow selected agents to be placed in a new array, but have mutation and crossover in half. **This will fit especially well with G-MSE given that agent strategies might not be expected to change much from one time step (of the model, not the genetic algorithm) to the next. Hence, the optimal solution from the previous time step will be included in next time step, and if nothing changes, then convergence will occur as soon as possible.**

It will obviously be important to run diagnostic tests on the G-MSE genetic algorithm. @Hamblin2013 recommends,

> ''Plots of mean population fitness (and its variance) and the fitness of the best individual over time can be important for both diagnostic and reporting purposes; populations that reach a single solution (close to zero variance) within a few generations are a clear sign of premature convergence, likely stemming from a problem in the balance of exploration and exploitation (selection too strong, too little mutation/crossover, population size too small, etc).''

Testing shouldn't be too difficult -- the results of genetic algorithms can be printed off to a c file, then read in by R and presented in a figure. @Hamblin2013 suggests that genetic algorithms are robust, so it's unlikely that parameter values choices will cause major problems or affect things greatly, but it's worth doing all of the quality checks.

> <a name="u-30-JAN-2017">Update: 30 JAN 2017</a>

**More review of utility functions in genetic algorithms**

I'm turning now to the use of utility functions, particularly the use of them in genetic algorithm and games. It appears that these can be found in economics and business. For example, @Luo2014 address an optimsation problem for product demand using a utility function to be maximised and a genetic algorithm. @Luo2014 use [fuzzy numbers](https://en.wikipedia.org/wiki/Fuzzy_number) to model market segements, which include three numbers representing most pessimistic, most likely, and most optimistic values. The authors use [conjoint analysis](https://en.wikipedia.org/wiki/Conjoint_analysis_(marketing)), apparently a technique to figure out what people will pay for, combined with a 'part-worth utility model'. Utility is modelled as a USD amount, and as a linear function (summation) of the product of weights, part-worth utilities, and a binary variable linking product profiles and product attributes -- summations over levels and product attributes. I'm not too worried about the details here, just that total utility is measured in currency in this case, and is calculated as weighted sub-utilities -- this kind of logic is relevant for G-MSE.

@Luo2014 then go on to model how utility determines a consumer's choice of product (essentially, consumers pick the product of highest utility, or none at all). Several constraints on product choice and product attribute-profiles are noted in the model, but the genetic algorithm is implemented using `int` coding -- one chromosome has consumer choice and product configuration sections. Genes within the consumer choice section each represent consumers in a particular market segment -- values of these genes correspond to choice of different product profiles (if the value is zero, no product is chosen). The product configuration section contains subsections related to product profiles; each subsection has genes whose integer values indicate the level selected for a product attribute. A population's gene values are initialised randomly, and individual fitness is calculated using the linear models introduced prior to the genetic algorithm. The authors use a uniform [crossover procedure](https://en.wikipedia.org/wiki/Crossover_(genetic_algorithm)), which might be useful type of algorithm -- apparently searching a lot of strategy space, though the costs and benefits of different crossover methods are still unclear to me. Parameters for the genetic algorithm seemed unusual, to me at least; @Luo2014 set a population size of 30, a crossover probability of 0.7, and a mutation probability of 0.4. I would have considered the population size much too low, and the mutation probability much too high, but it's worth keeping in mind that perhaps these parameter combinations are useful in genetic algorithms even they appear odd biologically -- it's worth experimenting with them, at least (their Figure 2 suggests that my presumed ideal parameters might be on the low side for crossover and mutation). **Surprisingly (at least, to me), @Luo2014 conclusded that their algorithm had the best performance (in terms of profit maximisation) when ''crossover probability was 0.7 and mutation probability was 0.7''**. The authors used MATLAB to implement the genetic algorithm, so the might have been stressed on computation efficiency -- it took 85 seconds for 50 generations on a Pentium IV processor; had the analysis been run in c, it surely would have been faster. 

@Luo2014 do note that **''low mutation probability (e.g. 0.1) is a good choice'' for genetic algorithms** (as a biologist, of course, this seems very, very high!), but their problem was an exception because the space that needed to be explored was very large.  **The general take-home I get from this is that the relatively low mutation and recombination rates that we observe as biologists are probably not appropriate for a good genetic algorithm; higher ones should be used by default -- of course, this will require citation to reassure reviewers that this is standard practice.**

@Tu2000 look at genetic algorithms for negotiations among agents using utility functions, which is exactly the kind of thing that we're interested in for G-MSE. In addition to being a useful resource for showing an overlap between utility functions and genetic algorithms, this conference proceedings is very interesting in that it has interacting agents, and considers negotiation as ''a serch for an optimal negotation outcome with respect to the utility functions of each partner'' [@Tu2000]. I'm not sure if we've proposed it this way before, but given that I've been conceptualising the manager in G-MSE as a special kind of agent (and, in that sense, similar to stake-holders, but following its utility to make rules rather than work within rules to maximise utility), it would be very interesting if we could use a genetic algorithm and the manager agent's utility function to **optimise** negotiation outcomes in addition to management outcomes -- or perhaps, define ideal management outcomes as the optimal negotiation outcomes that maximise the interests of stake-holders. We could then use the manager genetic algorithm as a tool in real-world case studies where real or simulated stake-holders play the role of agents.

The use of automated negotiation strategies in online commerce appears to follow a protocol using simple sequential rules and threshold utility values. @Tu2000 created a generic framework for a genetic algorithm, implemented using Java. Three functions needed included mutation, crossover, and reproduction. The algorithm for selection seems a bit unclear. It appears that parent individuals (i.e., reproduction) is chosen based on probability, while selection of offspring simply draws the highest fitness offspring to become the next generation of parents? (''*The parent individuals are chosen with a probability proportional to their fintess and the operators are chosen randomly. From the new population of size $\lambda$, the $\mu$ individuals with the highest fitness are propogated into the next generation as parents''*). This isn't entirely clear.

The method by which agents reach a consensus is really interesting as way that an agreement -- e.g., a policy -- is reached. It occurs to me that there might need to be some utility in inaction as well -- rather, some cost associated with doing something as a consequence of low utility, though I'm not yet entirely sure how this would be implemented practically. Stake-holders have other interests, of course. The authors consider four types of scenarios on which negotiations take place:

 1. **No conflict** -- i.e., both agents have ''identical utility functions'', so the optimal outcome for each is the same.
 2. **Pure distributive** -- Completely opposite utility functions, so a gain for one agent is always a loss for the other.
 3. **Simple integrative** -- Contrary utility functions, but the importance of issues under negotiation are a bit different, so a compromise can potentially be reached.
 4. **Divorce** -- Similar to *Simple integrative*, but more complex and potentially resulting in many different outcomes.
 
@Tu2000 tweaked crossover and mutation probabilities to get best results (unfortunately, the exact values they used aren't reported anywhere in the proceedings, that I can find).  

> <a name="u-29-JAN-2017">Update: 29 JAN 2017</a>

**Sunday musings**

As a bit of an aside, I'm thinking about how [biological degeneracy](https://en.wikipedia.org/wiki/Degeneracy_(biology)) might fit in to the efficacy of management policies, given that multiple independent agents might affect a biological system in different ways. I think that degeneracy is interesting and probably greatly under-considered across all biological scales, but it appears entirely absent as a theoretical or practical consideration in conservation and the maintenance of ecosystem function. @Man2016 very recently developed the theory to quantify *degeneracy*, doing so while simulating networks of complex neoronal systems characterised by non-linearity -- specifically comparing degeneracy to *redundancy* and *complexity*, which were also defined mathematically. I think there's a lot of room for theoretical development on degeneracy, and a lot of scope for the application of degeneracy theory to big questions in evolutionary ecology, community ecology, and conservation biology. The modelling in G-MSE is general enough to be potentially able to address these kinds of questions, perhaps using the mathematical definitions introduced by @Man2016 for analysis of simulation results.

> <a name="u-27-JAN-2017">Update: 27 JAN 2017</a>

I've been doing a bit more literature review on the subject of genetic algorithms, particularly as applied to economic and social-ecological questions [e.g., @Balmann2000; @Ascough2008]. Given the need to keep things computationally efficient while also repeatedly updating agent strategies, I think it's worth defining `AGENTS` as an `integer` array (I'm not sure why `RESOURCES` can't also be one, actually, so it might be worth checking on this) instead of a `double`. Supporting this:

 - There is really nothing currently in the `AGENT` array that *needs* to be a non-integer. the closest thing is a parameter affecting movement, but this can be made into an `int`, I should think. It might also help if the parameter affecting `error` was continuous, though I'm not yet convinced it *must* be -- `error` could just be the probability of error from zero to 100, interpreted as 0 to 1.0 by increments of 0.01.
 - Similarly, there really isn't anything in `RESOURCES` that *needs* to be a non-integer either. The probabilities of removal (i.e., death) and growth (i.e., birth) are the closest, but I don't know if there's any good reason to have these be especially precise -- i.e., why not just have an `int` value from zero to 100, corresponding to a 0.01 to 1.0 probability of mortality later? That way, the whole array could be `int`. I suspect the same can be done for the birth parameter, though the case is certainly less convincing than for the agent array.
 
**NEW ISSUE 13: Switch agent array to type int** 
 
In light of the above reasoning, I think I'll plan to switch `AGENTS` to an `int` type, then see how this affects things. Using integers to define 'genotypes' that affect agent strategies would permit the use of [bitwise operators](http://graphics.stanford.edu/~seander/bithacks.html) to increase speed at a very computationally intense part of the model (genetic algorithm mutation and selection). The size of an `int` [must be](https://en.wikipedia.org/w/index.php?title=C_data_types&oldid=376652910#Size) at least 16 bits in c, so a signed `int` could correspond to $2^{15} - 1 = 32,767$ unique values -- plenty, I would think, for coding a sufficient number of strategies. I'll want to do a bit more digging to see how much this could be expected to speed up the genetic algorithm (see [here](http://softwareengineering.stackexchange.com/questions/207408/is-it-necessary-to-map-integers-to-bits-in-a-genetic-algorithm) ). Of course, if it's trivial, then using `double` and columns affecting behaviour is probably just fine. But if speed is an issue, a vector of `int` values could really be better than several columns of `double` values; I'm just not sure what would have to be sacrificed yet. Quick random number sampling will be needed.

**Having second thoughts about binary encoding**

I'm not entirely convinced yet, actually that [binary instead of real](http://www.obitko.com/tutorials/genetic-algorithms/encoding.php) encoding is needed. One advantage of real encoding, besides that it fits a bit more easily into the current data structure I'm using, is that it might converge on optimal strategies sooner even if the bitwise calculations are faster [@Salomon1996]. Note that phenotypes in bitwise encoding are affected by both the position and value of bytes, whereas phenotypes in real encoding are only affected by the value of real numbers [@Kumar2013]. There are some techniques to [map binary values to real numbers](http://webpages.iust.ac.ir/yaghini/Courses/AOR_872/Genetic%20Algorithms_03.pdf), though I've not yet found anything comparing the efficiency of binary versus real encoding, but @Salomon1996 argued that real encoding was the best choice of applying genetic algorithms to optimisation -- I think this might be the way to go, though I'll want to think about how crossing over and mutation will work efficiently. **I'm not entirely sure I do want to finish issue 13.** In the end, using `int` instead of `double` could cut the memory in half, but this would be almost useless for the `AGENT` array -- if it could be done for the `RESOURCES` array, it might be more useful, but R doesn't differentiate, so it really won't matter that much, if at all.

**REMOVING ISSUE 13: Convinced myself that this was a bad idea**

Note that @Balmann2000 writes that ''population size usually ranges between 10 to 50'', though from population-genetics perspective, this seems too small to me.


> <a name="u-26-JAN-2017">Update: 26 JAN 2017</a>

**Fleshing out the use of Genetic Algorithms for G-MSE**

I'm becoming more convinced that some sort of genetic algorithm is the best way to model the strategies of **all** agents, including managers and stake-holders. Here is a rough overview of how I see the next step of the software development process:

 - Insert columns into the `AGENT` data frame that represent utility values associated with each type of resource. This will effectively quantify how much of each resource managers and stake-holders *want*. For example, while managers might prefer a balance of resources (perhaps the average of stake-holders?), stake-holders might prefer to maximise only one resource with little or no concern for another (or to actually prefer some resource quantities to be minimised). The utility values of each agent will be used as variables in a *utility function*, which will calculate agents' *satisfaction* (or *happiness* or *contentness*) with a current situation of resource quantities (note: this utility function need not be linear -- for some stake-holders, I'd expected it to be more log-linear, but it might be good to try different functions and ask real stake-holders what they think). Hence, a function `calc_utility` will be needed.
 
 - Insert another set of columns into `AGENT` that influences agent *actions* -- how managers and stake-holders will do *something* in their environment. This can be thought of as analagous to genes affecting an organisms phenotype in an evolutionary model, but will have different types of effects for agents:
    - Column values will directly affect manager decisions, establishing rules (i.e., the game) for stake-holders. A `manager` function will therefor be needed.
    - Column values will directly affect stake-holder actions -- i.e., how they will play the game. A `user` function will therefore be needed.
  
 - The second set of `AGENT` columns affecting manager and stake-holder actions will be updated before every decision using a [genetic algorithm](https://en.wikipedia.org/wiki/Genetic_algorithm). This will require a separate `opt_utility` function. This general function will work as follows:
    - Read in an agent (or a type of agent) and identify their utility values associated with each resource type (first new columns) and their actions (second new columns).
    - Read in the resources.
    - Read in the most recent observer estimates.
    - Read in the most recent game rules.
    - Use the `calc_utility` to calculate the utility of the agent of interest.
    - Use the agent of interest to produce a new data array of 10 pseudo-agents of the same type with randomised *action* variables. Next:
        1. For 20 generations
        2. Have each pseudo-agent produce 100 offspring with random recombination among pseudo-agents, and random mutation, for each *action* variable.
        3. Use the `manager` or `user` function for managers or stake-holders (perhaps need an R and C version of these functions -- c for here, R for later), respectively, to temporarily simulate each offspring's decision if used in one or more previous time steps (e.g., by using the current `AGENT` values)
        4. Use `calc_util` to find the utility associated with the simulated decision in 2 -- this effectively tests each pseudo-agent to see if their *action* variables are good at maximising utility.
        5. Grab the 10 pseudo-agents with the highest utility values and go back to step 2.
        6. If after 20 generations, mean utility values have not gotten sufficiently larger, stop and grab the pseudo-agent with the highest value -- its *action* variable values then replace those of the original agent.
    - The above could be speeded up by making one of the original pseudo-agents be the actual agent -- assuming strategies won't change much over time.
    
 - The above genetic algorithm can be used both for maangers maximising utility through establishing game rules and for stake-holders maximising utility by affecting resources. The idea is to have the general `opt_utility` to optimise what an agent does to maximise their utility through the use of a general genetic algorithm (perhaps simulating human planning, if it were as good as adaptation by natural selection, which I don't think it is).
 
 - This entire process will need to go into one `c` function for reasons of efficiency -- we're going to add some time onto these simulations, but I think it will be worth it provided we:
    - Consider some tricks for optimisation, such as using previous time step values as seeds in later time steps.
    - Make this process optional, with alternatives of specifying strategies *a priori* (perhaps empirically derived ones) and allowing the end user to input decisions as the simulation proceeds.
    - Are not too strict about convergence in optimisation -- I don't think we need to be, as we're not really trying to model **perfectly rational** agents so much as **intelligent** agents.

 - So, **perhaps**, the `manager.r` function will take in all of the necessary information and send it to c, and then c will go through the entire process of potentially automating manager interpretation of observation data and decision of making game rules based on manager utility values. Other management options will of course be available. 
 
 - Then, the `user.r` function will likewise take all of the necessary information and send it to c to go through the entire process of automating stake-holder interpretation of the manager's rules and updated actions based on stake-holder utility valuse. Other user options will of course be available.
 
 - This removes the need for a specific game arena, `games.R`, because the game is defined by `manager.r` and effectively played by users in `user.r`. The novelty is that we're using evolutionary game theory under the hood in both management and stake-holder actions to infer broader patterns about how cooperation and conflict might arise when all parties are acting according to their own interest.

I think this is getting on the right track, and I am starting to see how the code will look and run. We also might want to include a spatial component to all of this, affecting both manager and user actions. For example, perhaps some stake-holders can only have their utility functions affected by or act in resources within certain areas of the landscape.

> <a name="u-25-JAN-2017">Update: 25 JAN 2017</a>

**NEW ISSUE 12: Observe multiple times for density estimator**

Currently, estimating total population size using a sub-sample of observed area and assuming that the density of this sub-sample reflects global density (`method = case 0`) only works when one sub-sample is taken. There are multiple ways of fixing this so that the population size estimate takes into account multiple sub-samples. It would be a good idea to think about the most efficient way to do this and program it into R (perhaps with `tapply` to start, but eventually in the `manager.c` function, maybe).

**NEW ISSUE 11: Permanently move agents**

Allow agents to move in each time step, permanently, in some way. This might be best done through the `anecdotal` function. As of now, they go back to their original place at the end of each time step, and it would be good to have an option to let them move all around the landscape.

**Agent-based modelling in economics -- potentially useful ideas**

@Phan2003 briefly summarises the emerging (at least, at the time emerging) field of Agent-based Computational Economics, noting that agent-based models can complement mathematical theory in economics especially when equilibrium conditions cannot be easily computed or attained by agents. Relating agent-based models to cognitive economics, @Phan2003 notes that the latter ''is an attempt to take into account the incompleteness of information in the individual decision making process'', which seems especially relevant to G-MSE. The program [SWARM](https://en.wikipedia.org/wiki/Swarm_(simulation)) might be useful to explore -- written in java though. Software like SWARM, [MODULECO](http://www.gemass.fr/dphan/moduleco/english/moduleco12.htm), and [CORMAS](http://cormas.cirad.fr/en/outil/presentation/) appear to have a similar interface as G-MSE has (or will have), but I think that writing G-MSE from the ground up was definitely the right choice. This makes G-MSE more targeted to a specific social-ecological problem, allowing it to be written in a way that is computationally efficient, but can also be accessible through a browser by end users without proficiency in R (regarding efficiency, current simulation times for the model itself are: 100 time steps = `0.241` seconds, 1000 time steps = `3.179` seconds, and 10000 time steps = `27.740` seconds; I can't imagine anyone would want simulations longer than 1000 time steps, but the efficiency allows many replicate simulations in a time frame that will not be an issue for serious research -- especially if run in parallel. Things do slow a bit when more individuals are needed, but I've simulated 100 time steps with over 100000 individuals and found the simulation to take only `22.8` seconds. Memory might be an issue, but I'm currently storing entire resource and observation histories -- an option to not do this would cut back massively).

@Phan2003 discusses how agents might optimise behaviour over the course of some number of iterations, which appears analagous to evolution of traits, except that it's one individual essentially working through a trial-and-error process of finding the best behaviour to adopt to maximise some sort of utility function (in this case, profit). `Beliefs` are reported over time as numeric values that affect behaviour. @Phan2003 likewise considers the situation in which individuals buy or don't buy something to maximise a surplus via a maximisation function that multiplies a binary variable to the difference between costs and benefits of a good.

@Marks1992, in a now fairly dated paper, looked at modelling generalised prisoner's dilemmas, which involve continuous rather than discrete strategies, and discusses solutions for optimal strategies, including [evolutionary stable strategies](https://en.wikipedia.org/wiki/Evolutionarily_stable_strategy) as pioneered by [John Maynard Smith](https://en.wikipedia.org/wiki/John_Maynard_Smith). The general idea of the ideas in @Marks1992 has overlap with G-MSE, in that there are agents (perhaps rational agents) attempting to maximise something through interaction. @Marks1992 first introduces the oligopoly problem, stating, *''with a small number of competitive sellers, what is the equilibrium pattern of price and quantity across these sellers, if any?''* The analagy to managers and stake-holders would seem to be appropriate, perhaps: given a small number of stake-holders what is the equilibrium value of a set of resources (including population size, farm yield, etc.), if any? To do this we need to understand the agency of the stake-holders and the rules of the game as set by managers.

@Marks1992 considers an economic model of a generalised prisoner's dilemma with three players, considering the *genetic algorithm*, a machine-learning technique that makes it unnecessary for a human being to consider a strategy (i.e., the strategies are derived from the conditions of the model). **This is the kind of avenue that we want to go down**. In fact @Marks1992 puts it quite clearly in the block below:

> ''Mathematically, the problem of generating winning strategies is equivalent to solving a multi-dimensional, non-linear optimization with many local optima. In population genetic terms, it is equivalent to selecting for fitness''

Hence the overlap between evolutionary game theory and adaptive dynamics models with models that produce optimal strategies for maximising utility in economic situations appears to be quite large, as presumed. Therefore, using evolutionary game theory would appear to be a reasonable way of selecting stake-holder strategies in G-MSE. Delving a bit more into this literature might make the jargon clearer, and identify any subtle differences in the maths or algorithms though. And I'm still not sure how this fits in with machine learning (e.g., if *machine learning* is just adaptive dynamics under the hood -- a quick search doesn't give an answer to this, so I think it will be necessary to do a bit more reading to understand the two; @Marks1992 differentiates, ''[...] advent of [[Genetic Algorithms]](https://en.wikipedia.org/wiki/Genetic_algorithm) (and machine learning) means [...]''). [Here](https://www.burakkanber.com/blog/machine-learning-genetic-algorithms-part-1-javascript/) is an interesting example from a course in machine learning, where the instructor first looks at genetic algorithms -- the instructor describes them as the ''least practical'' of machine learning algorithms in the course, but the instructor is also an engineer, so perhaps they'll be more practical (probably more general, if I'm thinking correctly) for solving G-MSE type problems. 

Perhaps one c function (e.g., `adaptive.c`) could go through a learning process of maximising utility for each type of agent (*each* agent might get intense, depending on how many agents there are). The rules of the game could be passed from `game.c` to `adaptive.c`, where `adaptive.c` also takes in the array of `AGENTS`. From the starting point of each agent's traits, agents within the program could reproduce themselves with mutation, the selection could minimise some cost function until some sort of maxima is acheived that results in agent trait values that havet he highest return on utility. The program `adaptive.c` could therefore take in `AGENTS`

| IDs | type1 | type2 | ... | see2 | see3 | G1  | G2   | ... | Gn   |
|-----|-------|-------|-----|------|------|-----|------|-----|------|
| 0   |  0    |  0    | ... | 0    |  0   | 0   | 0    | ... | 0    |
| 1   |  1    |  0    | ... | 0    |  0   | 0.2 | 1.1  | ... | -0.1 |
| 2   |  1    |  0    | ... | 0    |  0   | 1.0 | -0.1 | ... | -2.7 |
| ... |  ...  |  ...  | ... | ...  | ...  | ... | ...  | ... | ...  |
| N-1 |  2    |  0    | ... | 0    |  0   | 0.4 | -1.1 | ... | 0.9  |
| N   |  2    |  0    | ... | 0    |  0   | 2.1 |  3.0 | ... | 0.5  |

Where the table above is the data frame of `AGENTS` as it currently exists with additional columns `G1` to `Gn` that could hold real numbers that affect agent behaviour. A dummy data frame could be created that allows for `evo_time` generations of reproduction with mutation and selection for minimising a cost function in attempt to find appropriate values affecting components of an agent's strategy. I'm not sure how long such an algorithm would take, but I suspect that it could be optimised to not be painfully long -- different criteria could be set, e.g., to allow for a maximum number of evolving generations (the [aforementioned](https://www.burakkanber.com/blog/machine-learning-genetic-algorithms-part-1-javascript/) instructor suggests 1000) or some convergence criteria. **Essentially, each agent or type of agent would go through a process of *learning* an optimal strategy by creating a lineage of strategies, the descendants of which would be selected by strategy performance.** Note that given a convergence criteria, strategies might not *need* to evolve much in each time step of G-MSE -- the best strategy might be stable over time in some situations (and if we don't want strategies to change over time steps, the question of optimal strategy could be solved when *initialising* agents -- still the idea of allowing dynamic strategies seems interesting, and might be important if management is also changing).

While for some simulations, we'll want to take the time to allow evolution of optimal strategies, in others we might even embrace an imperfect strategies evolving as a consequence of short evolution times -- this might mimic the limited time that stake-holders have to consider a particular problem.



> <a name="u-24-JAN-2017">Update: 24 JAN 2017</a>

**A general summary of G-MSE as it exists at the moment**

 - We have a working population model that is individual-based and allows for multiple types individual movement, birth, and death.
 - We have an observation model with four types of possible observation
 - We have a working option to allow end-user dynamic inputs while the simulation is going on, 'playing' as a manager/stake-holder
 - The code is flexible enough that we should be able to add to it as need be without restructuring everything.
 - The code appears to be bug-free; it doesn't crash when used correctly (though some error messages could be added)
 - The code is efficient: computationally intense tasks are passed to C, while tasks done in R are now coded with proper memory management in mind

**A summary of some of the challenges of putting the 'G' in G-MSE**

 1. The possible number of game categories increases exponentially with the number of actions, meaning that game solutions are [only available for simple cases](#u-18-JAN-2017) [@Adami2016]. How this affects G-MSE will depend on how many options are available to agents.
 2. Payoffs in G-MSE will [almost certainly](#u-18-JAN-2017) be [asymmetric](https://en.wikipedia.org/wiki/Symmetric_game), meaning that different agents might perceive themselves to be playing different games. This is a consequence of what evolutionary game theorists would refer to as ''genotype asymmetry'' -- as in, asymmetric caused by something that is inherent to the agent itself (as opposed to its location).
 3. Resources in G-MSE [might be](#u-19-JAN-2017) asymmetric, meaning that some agents (stake-holders) have an inherent advantage over others, allowing them to dominate interactions.
 4. Payoffs are expected to be stochastic -- or, rather -- there will be some variation around *expected payoffs* that might affect agent decision making and management outcomes.
 
**A summary of some ideas for moving forward with G-MSE**

 1. As an option, write up the model to allow for [*participatory agent-based modelling*](#u-20-JAN-2017). This would be beneficial in allowing experimentation and therefore having some empirical data on how stake-holders might make decisions, which could then parameterise a decision-making agent in the model. The downside is that decisions would not be well-grounded in theory -- we wouldn't have a clear idea of why they were being made based on game theory. Hence, some sort of game-theoretic derivation of decision rules is needed.
 2. [Evolutionary game theory](https://en.wikipedia.org/wiki/Evolutionary_game_theory) might be useful in deriving strategies for agents to play. I can imagine borrowing from the game-theoretic or [adaptive dynamics](https://en.wikipedia.org/wiki/Evolutionary_invasion_analysis) literature to allow strategies to optimise over time to maximise agent payoffs. This might be challenging if optimal strategies depend on game history (i.e.,  if we allow for strategies based on [extensive-form games](https://en.wikipedia.org/wiki/Extensive-form_game). Perhaps what we want instead is something more like a [chess engine](https://en.wikipedia.org/wiki/Chess_engine) (e.g., [Stockfish](https://github.com/official-stockfish/Stockfish), which is publicly available though written in C++, though [some engines](https://github.com/search?l=C&q=chess+engine&type=Repositories&utf8=%E2%9C%93) are written in C -- the general idea of these engines is to consider the rules and look forward to evaluate options, *pruning* branches of moves that are evaluated as bad, as *solving* for the best move is impossible given the sheer number of possible positions).
 3. Incorporate [economic game theory](https://en.wikipedia.org/wiki/Game_theory#Economics_and_business), and more specifically [agent-based computational economics](https://en.wikipedia.org/wiki/Agent-based_computational_economics), which incorporate [utility functions](https://en.wikipedia.org/wiki/Utility#Functions) to allow agents to make decisions. This would link nicely to the more social part of the social-ecological modelling, and is a bit away from my comfort zone, so it's probably good to consider in more detail. Perhaps some game-theoretic model that cleverly incorporates both evolutionary and economic applications of game theory could be good.
 4. Of slightly lesser concern, but worth mentioning, maybe consider the potential scope for applying complexity theory to management. I've been particularly thinking about how [biological degeneracy](https://en.wikipedia.org/wiki/Degeneracy_(biology)) might apply to social-ecological modelling (among other things), leading to more robust management decisions by explicitly considering the possibility of multiple components of management fulfilling overlapping functions, hence leading to greater stability or robustness. Degeneracy is defined by dissimilar components of a system performing similar functions (note, different from *redundancy*, which implies complete interchangeability). Degeneracy is ubiquitous in complex systems, but its importance has been largely overlooked -- I wonder if there is a case for thinking about it here, particularly with multiple agents and scales.
 
**Short-term plan**

I'm going to finish developing thoughts on evolutionary game theory, then move onto looking at game theory from an economic perspective. I think the biggest thing to consider on the immediate horizon is **what kind of approach will be used to simulate agents (stake-holders) playing games and making decisions**. Once this is clear, the details can follow. Some sort of utility function will be used. Of particular consideration is **how much complexity should be incorporated -- or, perhaps -- how much mechanistic detail**.

@Leombruni2005 makes some interesting points regarding use of mathematical versus agent based models, noting the tractability issues with mathematical (and game-theoretic) models as things become more complex due to unique individuals needing to be represented.

**Quick efficiency fix**

The best way to manage memory in R is going to be by avoiding `Rbind` altogether and working instead with lists, as made very clear by the following quick experiment in `scratch.r`:

```
################################################################################
# Testing list versus array efficiency

# ARRAY FIRST:
sam <- sample(x = 1:100, size = 14000, replace = TRUE);
dat <- matrix(data=sam, ncol=14);

obs <- NULL;

proc_start <- proc.time();

time <- 1000;
while(time > 0){
   obs   <- rbind(obs, dat);
   time  <- time - 1;
}

proc_end   <- proc.time();
time_taken <- proc_end - proc_start;
# TIME TAKEN: 14.09 seconds

# NOW LIST:
sam <- sample(x = 1:100, size = 14000, replace = TRUE);
dat <- matrix(data=sam, ncol=14);

obs <- list();

proc_start <- proc.time();

time <- 1000;
elem <- 1;
i    <- 1;
while(time > 0){
    obs[[i]] <- dat;
    i        <- i + 1;
    time     <- time - 1;
}

proc_end   <- proc.time();
time_taken <- proc_end - proc_start;
# TIME TAKEN: 0.005 seconds

################################################################################
```

The output being deposited into a list is much, much faster. Enough to make me want to fix this immediately. Doing so was trivial -- it was just a matter of replacing `RESOURCE_REC <- rbind(RESOURCE_REC, RESOURCES)` with `RESOURCE_REC[[time]]  <- RESOURCES`, then editing the plotting functions accordingly given the new data type. The result is that simulations are now *much* faster, especially when `time` is high, simulating many time steps. One hundred time steps used to take 10-12 seconds for some observation times -- they now all take under a second. For more time steps, the efficiency difference would increase exponentially. The massively increased efficiency occurs because R now no longer allocates a whole new massive chunk of memory for each new recorded data frame -- it just appends data to a list where the memory has already been allocated.

> **CONCLUSION** THE TIME IT TAKES TO RUN 100 TIME STEPS HAS DECREASED BY AN ORDER OF MAGNITUDE BY SWITCHING FROM DATA FRAMES TO LISTS IN R **(NOW LESS THAN 1 SECOND)**

Note that plotting still happens slowly, deliberately, because we're putting the system to sleep for a tenth of a second in each time step to make the animation smooth. When plotting is turned off, this no longer happens.

> <a name="u-23-JAN-2017">Update: 23 JAN 2017</a>

**Proof of concept: Interactive user input as a stake-holder**

The code below runs the `gmse` program in a way that is interactive. I have run time steps, and specified that the hunting begins in time step 95.

```
> sim <- gmse( observe_type  = 0,
+              agent_view    = 10,
+              res_death_K   = 400,
+              plotting      = TRUE,
+              hunt          = TRUE,
+              start_hunting = 95
+ );
```

This produces the following output. When prompted by the line ''`Enter the number of animals to shoot`'', I have typed in a number and hit enter accordingly.

```
Year:  95
The manager says the population size is  181
You observe  11  animals on the farm
Enter the number of animals to shoot
10

Year:  96
The manager says the population size is  408
You observe  11  animals on the farm
Enter the number of animals to shoot
10

Year:  97
The manager says the population size is  272
You observe  6  animals on the farm
Enter the number of animals to shoot
10
You can't shoot animals that you can't see
6  animals shot

Year:  98
The manager says the population size is  226
You observe  10  animals on the farm
Enter the number of animals to shoot
0

Year:  99
The manager says the population size is  294
You observe  9  animals on the farm
Enter the number of animals to shoot
5
```

The output of this also shows the spatial distribution of resources and a population graph over time. My hope was that allow the `gmse.so` file to be sourced directly from a link so that it could be run by anyone remotely, but I think that this will take a bit more work -- worth keeping in mind for later.

![*Population dynanics (black line) and manager estimate of population size (blue line) over time in a simulation in which the user can act as a stake-holder and shoot animals*](images/23-JAN-proof-of-concept.png)

I am still trying to get a clear picture on how to incorporate management, user, and game-theoretic modelling components. Given uncertainty in all of these components, some unified approach would seem beneficial. @Franco2016 has recently introduced a comprehensive approach to evaluate effects of disurbance on coral reefs using a [Bayesian Belief Network](https://en.wikipedia.org/wiki/Bayesian_network) (BBN) approach. This approach ''offers a methodological framework to address uncertanty.'' This approach requires some defined outcome state, the probabilities of realisation of which are calculated. Use of BBNs requires an acyclic graph and conditional probability tables.  It's not entirely clear to me how BBNs would be incorporated into the G-MSE simulations, except maybe as a type of observation model? With the simulation, we can look at causality directly and thereby quantify direct and indirect effects, and measurement error. It could, however, be useful to know how well BBNs perform using simulated populations, simulated observational data, and appropriate analysis based on BBNs, as would be used on empirically derived data.

> <a name="u-22-JAN-2017">Update: 22 JAN 2017</a>

For coauthors, add the G-MSE files onto a public Dropbox so that they can be [sourced](http://stackoverflow.com/questions/7715723/sourcing-r-script-over-https) and run remotely. There are also some useful resources for [embedding](http://fabian-kostadinov.github.io/2015/09/21/embedding-r-in-a-website/) R in a website. This might be faster than using Shiny, at least at first, so it could be useful for initial demonstrations. It might be useful to show a prototype of G-MSE, or what it might be:

```{r, echo=FALSE}
print("Managers estimate the population size is 4230");
print("You encounter 35 animals around your farm");
print("Estimated loss of yield is at 5%");
print("Enter how many animals you intend to hunt");
```

Demonstrating this (and it would be quick to implement) might be useful for showing how management and games work.

> <a name="u-20-JAN-2017">Update: 20 JAN 2017</a>

**Side note about computation efficiency**

Note that it would really be faster to convert to a list type in R if anything computationally intense needs to be done (e.g., binding rows). C will not appear to let me read in a list via `.Call`, only a vector, so it's worth thinking later about whether doing some things on the R side will be faster:

 1. Using the returned arrays from C
 2. Changing arrays to lists and then using them in R
 3. Making new C functions to do some standard R tasks faster (unlikely to work well)
 
Updated scratch.R to show how option 2 could work, though the change itself might be more inefficient than binding or other operations.

**Issues related to agent-based complex modelling of human decisions**

@An2012 reviewes humans as agents in agent-based models of social-ecological systems. @An2012 ties this in with complexity theory, and distinguishes *agent-based* from *individual-based* models in a useful way -- with agent-based models being defined more by attention to decision making processes (as in models of human behaviour). @An2012 asks,

> (a) What methods, in what manner, have been used to model human decision-making and behavior?
> (b) What are the potential strengths and caveats of these methods? 
> (c) What improvements can be made to better model human decisions in coupled human and natural systmes?

@An2012 reviews nine different types of decision models, and notes that different types of decision models can be mixed and matched, as we'll likely need to do for G-MSE. I'm not sure that we can assume that stake-holders are the same types of decision-makers. For example, I suspect that farmers might be better represented by a microeconomic model of decision making, with a focus on maximising some sort of revenue or yield. @An2012 notes the use of utility functions here (seeming to link with some of my [earlier thoughts](#game)), including one in which ecological indicators are included in place of just money [@Nautiyal2009]. Apparently, econometric work by @McFadden1973 is foundational to looking at decisions based on utility, modelling decisions as a probability of an agent choosing an option. @An2012 notes that decisions are unlikely to be completely rational, and humans will tend to seek ''satisfatory rather than optimal utility''. 

A second of the nine types of decision models includes the *psychosocial and cognitive models*, which attempt to model individual's thoughts based on beliefs and goals -- institutions can also be modelled this way, though we might think of institutions as collections of the same type of individual for the purposes of G-MSE coding.

**One type of modelling that could be especially interesting** is what @An2012 defines as ''participatory agent-based modelling'', wherein real stake-holders tell the modeller what they would do under some set of conditions conditions, then the model runs with those decisions. This has been used, apparently, in an agricultural setting [@Naivinit2010], and would be a very interesting addition to G-MSE. If we could have an option for letting a user *take over* the role of an agent in the model and play against a computer, it could be interesting -- though I'd tend to still want to develop some game-theoretic algorithm that grounds predictions of stake-holder behaviour, rather than relying solely on empirically derived data (i.e., asking people what they would do). This could be accomplished in a couple ways, in principle -- one being throught he use of a C standalone program (i.e., not linking with R) that prompts the user for input using the `scanf` function and repeatedly updates the simulation with information in every cycle of the G-MSE loop. The same effect can be accomplished in R with the following code as an example of the concept:

```{r}
act_agent <- function(times){
    while(times > 0){
        cat("\n\n\n How many geese do you shoot? \n\n");
        shot_char   <- readLines(con=stdin(),1);
        shot_num    <- as.numeric(shot_char);
        gross_prod  <- rpois(n=1, lambda=100);
        net_prod    <- gross_prod - (2 * shot_num);
        cat("\n");
        output      <- paste("Net production = ", net_prod);
        print(output);
        times       <- times - 1;
    }
}
```

If you read the function into R, then run it (e.g., `act_agent(times = 2)`, it will ask for input `times` iterations, prompting once per iteration of the `while` loop. An option in G-MSE would be nice to allow:

 1. Users to let the program run with stake-holders simulated by well thought out utility functions applied to a game.
 2. Users allowed to interact with the program in each time step such that every time an agent needs to make a decision, the user is prompted to doing so for one type of agent
 3. Multiple users prompted to enter in decisions, simulating a long history of real-world actors making choices in a simulated game.
 
All of these would be fun, and @An2012 notes that they are often quite useful Ideally it would be nice to make the program more user-friendly than a command line interface, but that seems like a concern for a version 2.0, after an initial version has been released. More helpfully, using some sort of loop could make for easy input of the R options in the `gmse` function -- it could ask, in plain language, for users to insert the numbers that are currently only input within `gmse()` itself (e.g., `gmse(time_max = 100)`). 

It's possible that we could develop a type of rudimentary artificial intelligence by collecting data of user decisions (i.e., make a 'bot' that *mimics* human decisions). For example, we could have 100 people act as agents in G-MSE, collect data on the decisions that they make when trying to act like a stake-holder, then construct an algorithm based on real user decision in different situations (alternativley, or in addition, we could also look at *actual* past decisions from the case studies to make an algorithm). This could be an interesting, approach, albeit a somewhat atheoretical one -- it doesn't excite me quite as much, but it might be worth considering because the end result might predict human behaviour better than theory-driven approaches (as humans don't always act rationally or think things through carefully -- *I don't think a citation is needed for this; it's 20 JAN 2017, and the current time is 17:00 GMT, or 12:00 EST*). It could also be interesting to compare different types of approaches (i.e., have a *theory-based approach* and a *empirically-based approach* option). @An2012 warns though that ''Even though also based on data, researchers usually have to go through relatively complex data compiling, computation, and/or statistical analysis to obtain such rules'' @An2012 also notes that this kind of data collection does not necessarily identify *why* decisions are being made. Hence, I do think game-theory will be absolutely important, with agents using underlying utility functions to maximise their own utilities as a consequence of games.

> <a name="u-19-JAN-2017">Update: 19 JAN 2017</a>

**Some notes on the asymmetric nature of stake-holder games**

Games between stake-holders, modelled by `agents` in G-MSE, are typically, if not always, going to be *asymmatric*. This means that the stake-holders are distinguished by more than their strategies -- they are likely to have their own unique payoffs defined by their identities (e.g., as a conservationist, a farmer, etc.). It would seem as though the only way around this -- if it's even possible -- might be to make identity *part of the game itself*. In other words, let agents attempt to maximise some general payoff *by deciding to take on a particular role*, and then a strategy given their chosen role. It's an interesting thought, but I don't think it makes much sense for the practical application of G-MSE. In the context of the games that we're interested in, stake-holders effectively **are** conservationists, farmers, hunters, etc. (or some mixture of these roles). Hence, I think we need to work with the idea that the games our stake-holders play and that G-MSE will model are going to be asymmetric.

@MaynardSmith1976 outlined three specfic ways that games might be asymmetric (they were thinking about animal contests, but the general principles apply):

 1. **Pay-offs asymmetry**: Different players might stand to gain different amounts in the game -- e.g., perhaps mutual cooperation returns a higher benefit for one player than another, or defection on the part of one player has a more negative effect on its opponent than vice versa. 
 
 2. **Resource asymmetry** Intrinsic difference between players might give one player an inherent advantage, allowing them to dominate in an interaction (i.e., there might not be much of a conflict because one side can always win).
 
 3. **Uncorrelated asymmetry** Discussed [earlier](#u-18-JAN-2017): @MaynardSmith1976 define this as asymmetries that ''do not affect either the payoffs or the'' resources that might given one player an intrinsic advantage.

The authors offer some general conclusions about asymmetric gains with unequal payoffs, but these are really more about encounters of conflict, and perhaps not so applicabl to G-MSE. They state that, where payoffs are unequal but all parties have access to information, it is best to ''play high when you have more to gain and zero when you have less to gain''. In other words, if there is a lot to gain by sticking it out and fighting hard in an interaction, do it -- if there's not much to gain, then back off. Such contests are the central focus of @MaynardSmith1976, but the general conclusion that ''mixed strategies will be the exception'' when contests are asymmetrical would seem to apply more broadly. Given the many ways that a game can be asymmetrical -- rather, that a symmetrical game could be changed to asymmetrical -- it would seem likely that there are more ways that cause a strategy to become pure than not pure because there are more ways of adjusting payoffs to making one strategy the clear winner. This could simplify the game theory in G-MSE, in a sense, if mixed strategies do not require much consideration.

@McAvoy2015 recently emphasised the importance of asymmetry in evolutionary games, noting that **''cooperation may be tied to individual energy or strength, which is, in turn, determined by a player's role''**. This would seem to apply to social-ecological conflicts as well -- cooperation might reasonably tied to the power (economic, political, etc.) of stake-holders, meaning that it might be important to take this into account in G-MSE modelling. For something like Prisoner's dilemma, we can represent an asymmetry using subscripts, so the standard game would be represented by a payoff matrix,

$$
\left( \begin{array}{ccc}
      & C    & D \\
    C & R, R & S, T \\
    D & T, S & P, P \end{array} \right).
$$

Where the above satisfies: $T > R > P > S$. An asymmetric game can be represented by,

$$
\left( \begin{array}{ccc}
      & C    & D \\
    C & R_{i}, R_{j} & S_{i}, T_{j} \\
    D & T_{i}, S_{j} & P_{i}, P_{j} \end{array} \right).
$$

The above is for two different types of players, $i$ and $j$. Note that I tried working through the [same basic concept](#game) with a bit different notation earlier on, with each matrix element being defined by a utility function that is unique to each agent type. In the code, this will all be defined by agent types and their respective traits (columns in the `agent_array`), but it's good to link this up with theory and the general properties of asymmetric games.

@McAvoy2015 go into the Prisoner's Dilemma and Snowdrift gamse given environmental and genotypic asymmetry

 - *Environmental asymmetry* refers to asymmetry in payoff matrices caused by differences in individual location.
 - *Genotypic asymetry* refers to asymmetry in payoff matrices caused by differences in individual genotype, which we can probably think about as differences in type that are intrinsic to the individuals and are not spatial (e.g., stake-holder roles).
 
Such asymmetries can complicate evolution of strategies, and, perhaps more relevant for G-MSE, can cause different types of agents to experience **different types of games** as a result of asymmetry:

> ''[...] Thus, based on the social dilemma implied by the ranking of the payoffs, a player who incurs a cost of $c_{1}$ for cooperating is always playing a Snowdrift Game while a player who incurs a cost of $c_{2}$ is always playing a Prisoner's Dilemma. It follows that ecological asymmetry can account for multiple social dilemmas being played within a single population, even if the players all use the same set of strategies'' [@McAvoy2015 p. 9].

The above quote is respect to asymmetry payoffs caused by space, but the point is that the asymmetry of the payoff matrix can lead to different players experiencing different games and therefore having different -- potentially conflicting -- strategies. 

We might also apply the concept of genotypic asymmetry with the process of **cultural updating**, which occurs when the 'genotypes' (perhaps stake-holder types) do not change, but the strategies of players can be updated over time. Note that genetic asymmetry can be reduced to a broader symmetric game given genetic updating (i.e., births and deaths of players of particular types), this is probably not applicable to G-MSE.

> <a name="u-18-JAN-2017">Update: 18 JAN 2017</a>

**Some thoughts on the application of game theory**

I'm trying to step back a bit to consider the manager and user models, which will both affect and/or be affected by the game-theoretic component of the model. I've considered how the game-theoretic component will fit into G-MSE [more generally](#soft), and also a bit of how it might be [implemented](#game) and [applied](#gamemod) in the context of stake-holder actions. Overall, this will require three c files to be closely integrated, but the application (perhaps even development, if necessary) of game theory requires a lot of thought. 

The model will be more general if we allow agents to take any number of actions. but the number of games that are possible increases exponentially with the number of different actions that agents can take [@Zeeman1980]. If only two actions are possible (e.g., cooperate and defect), then there are only four types of games that can be played (Prisoner's dilemma, Snowdrift, Anti-coordination, and Harmony). The number of games increases to 20 for three actions and 228 for four actions [@Adami2016]. If we want the software to somehow identify the *type* of game being played -- rather -- if game type identification is to be an essential part of the program, then agent actions will probably need to be limited (there is of course, always the option to identify games iff there are sufficiently few actions). If most conflicts can be described by a small number of types of agents with a small number of types of actions (and this seems reasonable, perhaps, especially if we think of actions qualitatively), then constraining the software to such cases might be preferable (at least, as a starting point). The benefit is that we might then make clearer predictions for management, e.g.: *Right now, stake-holders are playing a Snowdrift game, but by adopting an alternative management decision, they will transition to playing Harmony*. 

This is appealing, but I think it also relies on payoff matrices being [symmetric](https://en.wikipedia.org/wiki/Symmetric_game), meaning that players are distinguished by their strategies and nothing else [@McAvoy2015]. In the types of games that interest us, this almost certainly won't be true. The games we're interested in at ConfooBio will typically be characterised by [uncorrelated asymmetry](https://en.wikipedia.org/wiki/Uncorrelated_asymmetry); that is, situations in which agents know that they are of a certain type and will receive payoffs associated with that type of agent. Hence, the payoff structure might look like a Prisoner's dilemma to one stake-holder, but Harmony to another (i.e., the optimal strategy is always cooperate for one, but always defect for another *because each knows the type of agent that they are and how payoffs differ between types*).

I'm starting to work through these ideas with an initial focus on evolutionary games, as this is the application of game theory with which I'm most familiar, and because I think some of the general developments of evolutionary game theory are probably applicable for our purposes. I'll also need to read more widely into economics and the social sciences, but some recent work by @Adami2016 and @McAvoy2015 seems relevant.

@Adami2016 argue that the optimal strategies predicted by simple mathematical games are unlikely to be very useful for predicting agent actions given the complexities associated with decisions of real-world; such complexity notably includes stochasticity, which applies to games among all kinds of agents from ''microbes to day traders'' [@Adami2016]. Stochasticity can affect the stability of strategies [see also @Adami2013]. If strategies are conditional or based on memory of previous encounters, then the number of `traits` [@Adami2016 assume loci, modelling genetics, but the same applies to agents making decisions] required to model decisions increases rapidly -- 21 total traits are needed for conditional expression of strategy when agents can remember the previous two games. In practice, I suspect that there is some helpful way to simplify this -- perhaps not every detail of the history of interactions and possible conditions really is needed to (or even would be expected to) model stake-holder behaviour. Instead, I suspect that game history could be boiled down into one or two representative variables that, among other things, are likely to influence agent behaviour. Agents are perhaps better to be thought of as modelling stake-holders guided primarily by heuristics rather than optimally rational behaviour? Hence the `agent_array` might better be thought of as containing variables underlying human values and traits *in the context of games* rather than *as solutions to games*. A couple recent and potentially relevant papers on decision rules in complex environments include @Fawcett2014 and @McNamara2014. @Adami2016 conclude that **''[w]hile evolutionary games can be described succinctly in mathematical terms, they can only be solved exactly for the simplest of cases''**. @Adami2016 were specifically considering games in an evolutionary context, but I don't think that their conclusion is limited to evolutionary game theory. In the case of decision making stake-holders, the complexity associated with stochasticity and uncertainty, the possibility of more than two actions and payoffs, and the asymmetry of payoff matrices would all seem to conrtribute to the difficulty or impossibility of solving for exact solutions. Hence, when scenarios are complex in G-MSE (as we probably need them to be), it is unlikely that analytic solutions will be of much use. However, stake-holders won't evolve in the same sense as biological organisms, so some techniques used in evolutionary game theory will be unavailable -- or have to be modified. *It might be worth thinking more about identifying the consequences of practical or observed strategies, or types of strategies, rather than trying to somehow solve for the best strategies*. The [Axelrod experiments](https://en.wikipedia.org/wiki/The_Evolution_of_Cooperation#Axelrod.27s_tournaments) kind of did this before a lot of complex techniques became available to analyse evolutionary games. Users proposed strategies, which were put into a tournament -- the point wasn't so much to *solve* the [iterated Prisoner's dilemma](https://en.wikipedia.org/wiki/Prisoner's_dilemma#The_iterated_prisoner.27s_dilemma) so much as to explore different strategies for playing the game. 

In [this browser app](http://www.iterated-prisoners-dilemma.net/), you can play the iterated prisoner's dilemma against 'Lucifer', an automated agent that response to your decisions.


> <a name="u-17-JAN-2017">Update: 17 JAN 2017</a>

**NEW ISSUE 9: Observation Error** It would be useful to incorporate observation error into the simulations more directly. This could be affected by one or more variables attached to each agent, which would potentially cause the mis-identification (e.g., incorrect return of `seeme`) or mis-labelling (incorrect traits read into the observation array) of resources. This could be done in either of two ways:

 1. Cause the errors to happen in 'real time' -- that is, while the observations are happening in the simulation. This would probably be slightly inefficient, but have the benefit of being able to assign errors specifically to agents more directly.

 2. Wait until the `resource_array` is marked in the `observation` function, then introduce errors to the array itself, including errors to whether or not resources are recorded and what their trait values are. These errors would then be read into the `obs_array`, which is returned by the function.
 
**NEW ISSUE 10: Multiple resource**
 
The resource-wide parameter values (e.g., carrying capacities, movement types) will need to be either:

 1. Defined at the individual scale so that each individual resource has it's own value which can then be called in the `resource` function as necessary, and/or
 2. Input as vector in the base `gmse` function, the length of which could determine how many times `resource` is called in one time step (one for each type of resource, potentially, if carrying capacity is type specific -- or carrying capacity could be applied within a type in c -- perhaps more efficient, but would require to read in multiple `K` somehow, either through the `paras` vector or in the `resources` array -- or something else. How to do this best will need to consider both computational efficiency and clarity/ease of coding.

Note that:

 - `res_remove` can already be called in a type-specific way by `resource`, so it might just be better to call `resource` once and somehow input variable numbers of `K` into c. I'll need to think more about this, but it could be something like assigning each individual a competition coefficient `alpha` for how it is affected by each other type of individual. Intra-type competition could then be modelled generally, with `K` defined by its inverse. Meanwhile, inter-type competition coefficients could also be useful. 

 - Along these lines, it's also worth considering an option allowing only one resource per cell (equating to a local `alpha` and `K` of one). This might be worth making its own issue later.

 - If we were to call `resource` multiple times, we would also need to `paste` arrays together in `R`. This wouldn't be terrible, but it could lose some efficiency unnecessarily, and I don't see the benefit.
 
**MEMORY LEAK CHECK OF R CODE**

I have tried running simulations at very high population sizes (>100000) to see how the simulation would react. Upon seeing quite a bit of memory being used up, I ran the following `valgrind` command:

```
R -d "valgrind --tool=memcheck --leak-check=yes" --vanilla < gmse.R
```

The program `valgrind` found a lot of large memory allocations and deallocations (as expected):

```
Warning: set address range perms: large range
```

The leak summary was as follows:

```
==14507== LEAK SUMMARY:
==14507==    definitely lost: 133,373,728 bytes in 469 blocks
==14507==    indirectly lost: 11,472,512 bytes in 55 blocks
==14507==      possibly lost: 120,863,992 bytes in 563 blocks
==14507==    still reachable: 2,319,742,586 bytes in 12,127 blocks
==14507==         suppressed: 0 bytes in 0 blocks
==14507== Reachable blocks (those to which a pointer was found) are not shown.
==14507== To see them, rerun with: --leak-check=full --show-leak-kinds=all
==14507== 
==14507== For counts of detected and suppressed errors, rerun with: -v
```

If we shift to look only at one run of the `resource` model, which is run in the new script `scratch.R`, we get:

```
==14689== LEAK SUMMARY:
==14689==    definitely lost: 3,584 bytes in 4 blocks
==14689==    indirectly lost: 0 bytes in 0 blocks
==14689==      possibly lost: 0 bytes in 0 blocks
==14689==    still reachable: 28,837,506 bytes in 13,346 blocks
==14689==         suppressed: 0 bytes in 0 blocks
==14689== Reachable blocks (those to which a pointer was found) are not shown.
==14689== To see them, rerun with: --leak-check=full --show-leak-kinds=all
```
 
And if we include one run of the observation model too, we get:

```
==14721== LEAK SUMMARY:
==14721==    definitely lost: 6,296 bytes in 8 blocks
==14721==    indirectly lost: 0 bytes in 0 blocks
==14721==      possibly lost: 0 bytes in 0 blocks
==14721==    still reachable: 28,948,434 bytes in 13,355 blocks
==14721==         suppressed: 0 bytes in 0 blocks
==14721== Reachable blocks (those to which a pointer was found) are not shown.
==14721== To see them, rerun with: --leak-check=full --show-leak-kinds=all
```
 
A bit more worrisome, if I run an old R script (a [simple individual-based model](https://github.com/bradduthie/EcoEdu/blob/master/Eco_Mod_IBM.R)), I get the following

```
==15050== LEAK SUMMARY:
==15050==    definitely lost: 0 bytes in 0 blocks
==15050==    indirectly lost: 0 bytes in 0 blocks
==15050==      possibly lost: 0 bytes in 0 blocks
==15050==    still reachable: 36,846,063 bytes in 15,996 blocks
==15050==         suppressed: 0 bytes in 0 blocks
==15050== Reachable blocks (those to which a pointer was found) are not shown.
```

Originally, I feared that this might suggest a problem with my c code, or its call to R. All the memory allocated appears to be freed though. Some [searching online](http://kevinushey.github.io/blog/2015/04/05/debugging-with-valgrind/) suggests that `valgrind` is not always perfect on this front.
 
> ''You may be surprised to see that valgrind believes that R has leaked memory - unfortunately, it is not perfect, and in this particular case the memory is not so much 'leaked' as it is 'cached for the duration of that R session', and valgrind fails to detect that 'ownership' of a particular block of memory is transfered.''

This is likely what happened (given the original warning). In fact, if we run `valgrind` and try to track the origin of the leak with `--track-origins=yes`, it complains in exactly the this way -- about memory that is allocated but definitely freed:

```
R -d "valgrind --tool=memcheck --leak-check=yes --track-origins=yes" --vanilla < scratch.R
```

Below, for example, `valgrind` is complaining about line 468 in the `resource.c` file:

```
==15171== 1,560 bytes in 1 blocks are definitely lost in loss record 165 of 1,867
==15171==    at 0x4C2DB8F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
==15171==    by 0xC2959DE: resource (resource.c:468)
==15171==    by 0x4F0A57F: ??? (in /usr/lib/R/lib/libR.so)
==15171==    by 0x4F4272E: Rf_eval (in /usr/lib/R/lib/libR.so)
==15171==    by 0x4F44E47: ??? (in /usr/lib/R/lib/libR.so)
==15171==    by 0x4F42520: Rf_eval (in /usr/lib/R/lib/libR.so)
==15171==    by 0x4F43DDC: Rf_applyClosure (in /usr/lib/R/lib/libR.so)
==15171==    by 0x4F422FC: Rf_eval (in /usr/lib/R/lib/libR.so)
==15171==    by 0x4F45FB5: ??? (in /usr/lib/R/lib/libR.so)
==15171==    by 0x4F42520: Rf_eval (in /usr/lib/R/lib/libR.so)
==15171==    by 0x4F44E47: ??? (in /usr/lib/R/lib/libR.so)
==15171==    by 0x4F42520: Rf_eval (in /usr/lib/R/lib/libR.so)
```

This line allocates memory for the `res_new` array:

```
res_new = malloc(res_num_total * sizeof(double *));
for(resource = 0; resource < res_num_total; resource++){
    res_new[resource] = malloc(trait_number * sizeof(double));   
}    
```

**This appeared to be have been freed correctly, but on inspection, each `malloc` to an array was missing a correspondnig free** I have fixed this (with thanks to [this](http://stackoverflow.com/questions/1733881/c-correctly-freeing-memory-of-a-multi-dimensional-array) StackOverflow thread), and now the entire `gmse.R` program produces the follow `valgrind` output:

```
==15405== LEAK SUMMARY:
==15405==    definitely lost: 0 bytes in 0 blocks
==15405==    indirectly lost: 0 bytes in 0 blocks
==15405==      possibly lost: 0 bytes in 0 blocks
==15405==    still reachable: 1,544,824,322 bytes in 12,119 blocks
==15405==         suppressed: 0 bytes in 0 blocks
```

> **CONCLUSION** MEMORY LEAK HAS BEEN IDENTIFIED AND FIXED

While this wasn't a huge deal for small scale simulations, for simulations with huge arrays caused by large population sizes, this would have made a difference. The code has therefore been corrected and pushed to `dev`. 

With all of this in mind, it is worth thinking about the R side of memory management as it becomes more relevant (see [R memory management advice](http://adv-r.had.co.nz/memory.html)). It might be worth switching to a list structure for input and output so that entire frames are not copied for each operation (which I assume R is doing for the `rbind()` function). It might also be worth thinking about running `rm()` and `gc()` in tandem to release memory during the major loop -- or also getting rid of some components of the data frame on the fly. The `gmse.R` program could potentially switch from a `list` to an `array` after the major simulation loop finishes and plotting or returning the array is necessary.

It appears that [I'm correct](http://biostat.mc.vanderbilt.edu/wiki/pub/Main/SvetlanaEdenRFiles/handouts.pdf) regarding the use of `rbind()` (or `c()` or `cbind()`) -- these are terribly inefficient with respect to what's happening under the hood when R calls C (or C++). I've downloaded [Svetlana Eden's](http://biostat.mc.vanderbilt.edu/wiki/Main/SvetlanaEden) [Efficiency tips for basic R loop](http://biostat.mc.vanderbilt.edu/wiki/pub/Main/SvetlanaEdenRFiles/handouts.pdf), which might be a useful reference when working on the R side of optimisation. The `rbinds` really show be avoided, if possible. One way to do this, if nothing else, would be to write to a file instead of `cbind` (not sure if this would be helpful for a shiny app). [StackOverflow](http://stackoverflow.com/questions/15673550/why-is-rbindlist-better-than-rbind) suggests using `rbindlist`, but this would introduce dependencies that I'd prefer to avoid. **In the end, it might be worth it to just write a quick `add_data.c` script in c for the sole purpose of joining old and new arrays.** Alteratively, this might not be so important -- in the end, it might not even be necessary to record the entire observation history; at least, not in the way it's currently being done. The history might instead only record a few key things from each time period.


> <a name="u-16-JAN-2017">Update: 16 JAN 2017</a>

**RESOLVED ISSUE 6: Sampling ability with agent number** This issue has been resolved to my satisfaction. I did this using the second option of addressing it. Now for `case 3` in which blocks of the landscape are iteratively sampled (and resources potentially move in between iterations), a `transect_eff` defining transect efficiency is set as equal to the number of observing agents (`working_agents`). The `transect_eff` is a counter, which, after it has counted down to zero, will permit resource movement. Hence, if there is only one agent observing, `transect_eff` hits zero and movement happens after every iteration; if there are two agents observing, then `transect_eff` hits zero after two iterations, then movement occurs and `transect_eff` is reset to `working_agents`.


**RESOLVED ISSUE 8: Clear up method sampling type in observation model** This issue has been resolved, albeit with cases in a different order than suggested (the original suggestion, it turns out, was not ideal). Cases are now:

 0: Sampling with a range of view (i.e., don't rely on the fix_mark > 0 for switching methods)
 1. Sampling `fix_mark` times randomly on the landscape.
 2. Linear transect
 3. Square transect

Of course, there is always room for more, but these are now four clear observation methods. Separating `case 0` from `case 1` is especially useful now. Now the variable `fix_mark` is just ignored for all cases except 1. In the code, both `case 0` and `case 1` still look similar, and both dig deep through `mark_res` and `field_work` functions to differentiate between observation methods, but I don't think that this is necessarily a bad thing -- a different argument to `mark_res` differentiates them now, at least, in the `observation` function, so it's not too difficult to trace through what is going on. Note that both cases 0 and 1 add a new column for each `times_obs`, which isn't done for the transect methods.

**The specially created branch `fix_home_bug` has been merged. I will keep it alive for a while before removing it entirely.**

**Update -- 14:33**, after rewriting the `gmse.R` code to make an easier catch-all function, with appropriate analysis, I've noticed that the `binos` function in `observation.c` is defining distance in a way that is no longer *really* compatible with the ponit of `case 0` (i.e., sample a small area and extrapolate based on the density). The `binos` function was looking at the *Euclidean* distance, making, e.g., 3 cells away diagonally farther than 3 cells away left or right (or up or down). This might be useful later, so I'm going to keep it in as an option, but I'm also going to make the default now as *within `view` cells in any direction*, such that a block forms around the focal individual, and diagonal distances are not assumed to be longer than length and width. This is the more common way of simulating things, and it makes movement and observation estimates easier -- I think the only reason to change it back to Euclidean distance would be if we had an actual map and really needed to be precise with the distance of things on it.

**I have also simplified the master R file `gmse.R` to allow for one function to do all of the work, using several default options for simulations.** Below, the main `gmse()` function is shown with its default values.

```
################################################################################
# PRIMARY FUNCTION (gmse) FOR RUNNING A SIMULATION
# NOTE: RELIES ON SOME OTHER FUNCTIONS BELOW: MIGHT WANT TO READ WHOLE FILE
################################################################################
gmse <- function( time_max       = 100,   # Max number of time steps in sim
                  land_dim_1     = 100,   # x dimension of the landscape
                  land_dim_2     = 100,   # y dimension of the landscape
                  res_movement   = 1,     # How far do resources move
                  remove_pr      = 0.0,   # Density independent resource death
                  lambda         = 0.9,   # Resource growth rate
                  agent_view     = 10,    # Number cells agent view around them
                  agent_move     = 50,    # Number cells agent can move
                  res_birth_K    = 10000, # Carrying capacity applied to birth
                  res_death_K    = 400,   # Carrying capacity applied to death
                  edge_effect    = 1,     # What type of edge on the landscape
                  res_move_type  = 2,     # What type of movement for resources
                  res_birth_type = 2,     # What type of birth for resources
                  res_death_type = 2,     # What type of death for resources
                  observe_type   = 0,     # Type of observation used
                  fixed_observe  = 1,     # How many obs (if type = 1)
                  times_observe  = 1,     # How many times obs (if type = 0)
                  obs_move_type  = 1,     # Type of movement for agents
                  res_min_age    = 1,     # Minimum age recorded and observed
                  res_move_obs   = TRUE,  # Move resources while observing
                  Euclidean_dist = FALSE, # Use Euclidean distance in view
                  plotting       = TRUE   # Plot the results
){}
```

Using the function defined above, with most parameters set to default values, I looked at the four different observation types below given the following parameters.

```
# A: Sample of a 10 by 10 region to estimate density
# Simulation time: 1.8 seconds
gmse( observe_type = 0,
      agent_view   = 10,
      res_death_K  = 800,
      plotting     = TRUE
    );

# B: Mark 30 resources 4 times, recapture 30 4 times
# Simulation time: 2.1 seconds
gmse( observe_type  = 1,
      fixed_observe = 30,
      times_observe = 8,
      res_death_K   = 800,
      plotting      = TRUE
    );

# C: Sample agent_view rows at a time -- all across
# Simulation time: 2.3 seconds
gmse( observe_type = 2,
      agent_view   = 10,
      res_death_K  = 800,
      plotting     = TRUE
);

# D: Sample agent_view rows at a time -- all across
# Simulation time: 6.5 seconds
gmse( observe_type = 3,
      agent_view   = 10,
      res_death_K  = 800,
      plotting     = TRUE
);
```

These four simulations A-D, which had identical populations models and similar observation modes, produced the four graphs below.

![*Figure above shows four different observation types as applied to the same population model: (A) observation type 0 (sample a random region and then extrapolate population size by calculating density), (B) Mark and recapture individuals and estimate population size using a Chapman estimator, (C) sample along a linear transect while resources can move while sampling, and (D) sample blocks where resources can move while sampling*](images/16-01-2017_obs_types.png)

**Overall, these simulations have been stable throughout testing, and I am (finally) merging the `dev` branch to `master`, pushing to GitHub, and declaring this `v0.0.5`.**

> <a name="u-15-JAN-2017">Update: 15 JAN 2017</a>

**A couple updates that have been made, or need to be fixed. I'll do these tomorrow, as they probably won't require much more than a few hours in the morning**

I've created a new temporary branch, `fix_home_bug`, after noticing a crash from my home laptop. It seems that I hadn't initialised the `added` variable at zero in the `res_add` function of the `resources.c` file. At the office computer, it seemed to initialise it at zero automatically (or I'd not played with the right parameters to get it to crash), but at home, it was often getting initialised to very high values and crashing. I've fixed the issue on the new branch, but it needs to be merged.

**NEW UNRESOLVED ISSUE #8:  Clear up method sampling type in observation model** The `method` sampling for `case 0` is too confusing. Sometimes it means randomly sampled `fix_mark` individuals from the population, and sometimes it means sample within a particular range of view. Change this so that the `switch` functions have four clear cases:

 0. Sampling with a range of view (i.e., don't rely on the fix_mark > 0 for switching methods)
 1. Linear transect
 2. Square transect
 3. Sampling `fix_mark` times randomly on the landscape.

This will avoid a lot of hassle, even if the code for cases 0 and 3 end up looking the same, or very similar. It's just very confusing to manage as it is now.

**ISSUE #6 STILL NEEDS RESOLVING** I was working on this when I found the bug resolved on the new branch. It didn't take too long, and it should be an easy fix while I take care of issue 8.

**TIME ISSUES**: While the simulations run quickly in the office computer, 100 time steps now take about 8 seconds for the loop on my Lenovo Thinkpad X201 -- something to be aware of as the coding continues.

**FOR TOMORROW:** Make a summary that includes an example of all 4 types of observation models and their appropriate analyses (quickly fix the plotting to do the correct analyses automatically): 

 `case 0` View-based sampling in which the density is sampled and applied to the whole size of the landscape [as in @Nuno2013]
 `case 1` Mark-recapture sampling where there is some fixed number marked at each time and estimates show Chapman style analysis 
 `case 2` Sampling along a linear transect as resources move, and 
 `case 3` Sampling using blocks as resources move.
 
Some updated code is on the `fix_home_bug` branch, which can be merged into the `dev` branch once it's done and is stable after some testing in the office (i.e., try to crash it).

> <a name="u-13-JAN-2017">Update: 13 JAN 2017</a>

**Below shows a bit of additional coding, which resulted in two new ways (which is really just one flexible way) that observation can occur. There are couple trivial fixes and additions to make (see new issues 6 and 7), but these should be easy to implement. For now, it's time to take a step back and plan a bit more generally, especially with respect to implementing the game-theoretic component of the modelling.**

**RESOLVED ISSUE #5:  Sweep observation** This issue has now been resolved. There are now two additional ways to observer populations, as guided by the `method` variable used in the main `switch` of the observational model. In biological terms, the observational model allows us to sample in the following two ways:

 1. By sampling `view` rows at a time, starting from the top of the landscape and working down to the bottom. Each time a new row is sampled, resources on the landscape can move (resource movement can also be turned off if desired). Hence, it is possible for observers to miss or double count resources. The bigger `view` is, the fewer iterations of sampling are needed to make it all the way across the landscape, hence fewer total times resources will move over the course of sampling.

 2. Identical to 1, but instead of sampling a full row and working down, observers start in the upper left corner of the landscape and sample around a `view` by `view` block, and hence a total of `view^2` cells. Sampling proceeds with blocks across rows until sampling of the very right side of the landscape has occurred. After sampling all to the end of the right side, observers move down, sampling another row of `view` by `view` blocks just beneath the first. This continues until the entire landscape has been sampled, and roughly simulates an observer working their way through the whole landscape over time (time in which resources might move).

**Note: The first case is redundant, and therefore will probably be removed later, but it helped as a scaffold for the more general procedure and takes up little space; for now, I'll leave it**

Testing on both of the above cases was successful (see the figure below). In each case, if resources are not allowed to move, then observers predict resource abundance with 100 percent accuracy (i.e., they sweep through the landscape and count all of the stationary resources). If resource can move, there is a bit of (normally distributed, it appears, and should be -- can look later) error  around the actual abundance. Either of these two methods of observation work fairly efficiently until `view` gets very low (ca 2), in which case a lot of sampling happens in each generation.

![*Figure above shows a population model (black line) and a new observation model (blue line). The observation model was simulated by having one observer record all of the resources on a 10 by 10 cell block (100 total blocks), each one at a time, and between observing blocks, resouces were able to move *](images/obs_dev_eg_case2.png)


After each sampling, resources moved an average of ca 5 cells away, with a distribution as shown below (Figure below shows the distance that an individual moves in **one** time step -- between successive iterations of observer sampling along a transect. 

![*Figure shows the distance (in cells) travelled by a resource during one time step, between which observers sample. Movement is guided by a poisson function such that an individual moves a distance of `dist` a total of `Poisson(dist)` times in one time step. The figure above shows this for 1000 individuals.*](images/res_move_hist.png)

I did not code sampling using the initially considered method, with agents physically moved to locations and then looking around. Instead, resources are just considered counted if they are within the row or block under consideration. To account for multiple agents sampling, `view` **is actually first multiplied by the number of agents sampling (only 1 for now)**. This makes sense for case 1, but for case 2, sampling ability actually increases with the square of agent number, so this will need to be changed (*Adding a new issue*).

**INTRODUCE NEW ISSUE #6: Sampling ability with agent number**

In `case` two of the observational model, the length and width of a sampling block will both increase linearly with the number of agents doing the sampling; hence, sampling area increases exponentially with the number of observers, which is probably unrealistic. There are two ways to potentially address this:

 1. Simply add another square for each agent observing, in the next place it would otherwise go.
 2. Probably more easy, have a countdown defined by `+= (int) agent_array[agent][8]`. Only allow resources to move when this countdown hits zero, and reset it it thereafter. Hence, observers will observe more *n* more blocks if there are *n* more observers.
 3. Could adjust the squared dimensions appropriately to retain a square block, but this seems inefficient, imprecise (due to rounding), and unnecessary.
 
**INTRODUCE NEW ISSUE #7: DENSITY TYPE SAMPLING** 
 
Of course, it will be easy to make this kind of transect sampling *random* instead of comprehensive over the landscape. This can be done by simply randomly choosing the positions of block on a landscape some `obs_iter` of times. This could allow an estimate of population size by considering *density* (i.e., assume that the number counted in a sampled block reflects the density of the larger landscape of known size), as was done by @Nuno2013. This shouldn't take much time to code and test.

> <a name="u-11-JAN-2017">Update: 11 JAN 2017</a>

I'm going to start referring to issues that are introduced and resolved in the gmse GitHub repository by number.

**RESOLVED ISSUE #4: Repeat calls of resource within resourc.R** Now poorly named given the solution. The result is a brief update on the addition of a bit of a side function. The function `anecdotal` is now available in the `observation.c` file, and is called from the `anecdotal()` function in the file `anecdotal.R`. All this function does is cause agents of one or all types to count the number of a particular resource within the agents' view. It is similar to the `observation` function, but instead of returning an array of observations of resources (augmented with columns for different observations periods -- see [10 JAN](#u-10-JAN-2017)) that is intended to be used by R separately, the `anecdotal` function adds the number of resources viewed in an agent's vicinity to a column in the agent array. The name of the function therefore is meant to add to an agent's general mood or impression of the quantity of a resource, based on anecdotal evidence for what's going on around their location. We can imagine such anecdotal evidence as affecting the opinions and behaviours of stake-holders.

**INTRODUCE NEW ISSUE #5: Sweep observation** Related to discussions with Jeremy and Tom regarding the Islay geese, need to have a kind of observational model in which agents move to take measurements, but resources move along roughly the same time scale. This can of course be accomplished one way if we:

 - add an option for resource movement during the course of observation: Do this in the main observation function as an `if(resource_movement == 1)` type criteria at the tail end before the `break` (to avoid unnecessary movement). This will require also including the resource movement function (currently in `resource.c`) in the `observation.c` file. May as well just dump the whole thing in in the interest of modularity, though if it stays the same, it will be tempting to create a `utils.c` file of some sort. This resource movement option can be applied to the existing `method` `case 0`, as appears in the switch function of the `observation` function.

To do a sweep of the landscape while allowing resources to move, I think we'll want a completely different `method` of population size estimation (most upstream switch function). What this method will do is:

 1. Start an observer(s) in a fixed `x` location of `x = 0` on the landscape
 2. Have the observer(s) census all individuals on the `x` locations `x` to `x+view` (i.e., observe `view` rows) 
 3. Set a new `x = x+view`
 4. Move resources
 5. Iterate 2-4 until `x+view` is greater than the y dimension `land_y`
 6. If there are any ys left, then iterate the last `x` to `land_y`.

The procedure above will simulate observations over a time that is proportional to their `view` (and thus ability to census) -- the more time it takes, the more the resources can move and potentially lead to measurement error. The observational array returned will still be output in the same way -- resources will be marked as with the `case 0` option and read out as an observational array.

*Note: It would be nice to eventually allow for **blocks** rather than long linear transects to be sampled, as square blocks might more realistically correspond to the kind of sampling that would be done by a real observer. I don't think that this would make too much difference in terms of finding sampling error, as there is no bias to resources movement in one direction; hence, the turnover of resources for any particular number of cells will be the same for any `N` cells sampled. It also stands to reason that this error should be normally distributed as the number of sampling attempts becomes large, and the error should be mean centred around the actual population size, since the probability of missing and double counting would seem to cancel out exactly. This might eventually lead to analytical estimate of observation and error actually being reasonable under some conditions.*

**Plan for the near future**

I will try to implement this new idea tomorrow, as I don't think it will take much more than a day's work, if that. Then, it's really time to take a step back and think -- need to read @Nuno2013 in more detail first, perhaps tonight, and potentially also add the observation model procedure used therein as different implementations of `case` -- this should be very similar to the solution for *ISSUE 5**, except through the use of random sampling of area and density measuring of resources. We'll then be in a position of having a stable resource and observation model with a few different options for observation, and I'll need to think more carefully about the big picture, and how to proceed with the rest of the model.

> <a name="u-10-JAN-2017">Update: 10 JAN 2017</a>

We now have a working G-MSE `v0.0.4`, which includes a stable population model and a stable observation model. The figure below shows the visual output of the new version, with the landscape in the top panel (*note: different tan colours don't mean anything yet -- the landscape is effectively uniform*); resources (i.e., individuals in the population) are represented in black. In the bottom panel, the solid black line shows the actual change in (adult) population size over time, stabilising around a carrying capacity of 400 (red dotted line). The dark solid cyan line shows an estimate of the population size from the observation model, simulated through mark-recapture (other types of observation are available, see below). The shading around this line shows $95%$ confidence interval estimates. More details about this specific estimate [below](#10-JAN-2017-cmr-details).

![*Figure above shows population and observation models*](images/obs_dev_eg.png)

I've made a few minor updates to the population model code, and included one new type of movement that is allowed -- borrowed from individual-based modelling literature on plant-pollinator-exploiter interactions [@Bronstein2003; @Duthie2013]. This type of movement makes use of an individual's movement parameter `move` by having an individual move `Poisson(move)` times each time step, and with each movement travelling up to `move` cells away (Euclidean distance). This type of movement is `case 0:` in the `mover` function in `resource.c`.

This update includes the major addition of the `observation.c` file, called by `observation.R` to simulate the sampling of resources (i.e., individuals) from the population model. The file `observation.R` holds the `observation()` function, which **returns a data frame of observed resources. The observation function thereby simulates the process of acquiring observational data, but not analysing those data**. Analysis of these data is left to R, or to a (yet written) c function (note, current analyses are fairly simple).

The function `observation.R` **requires** the following three data frames: 

 1. `resources`: holds all of the resources simulated. 
 2. `landscape`: holds the landscape on which resources and agents are located.
 3. `agent`: holds all of the agents simulated (this also includes at least one manager of type 0 -- even if the manager does not eventually participate in games). 
 
The `observation.R` function also **requires** the `paras` vector, which holds all parameters that might be important throughout the simulation. 

Optional inputs include:

 - `type`, which specifies the type of resource being observed (default = 1).
 - `fix_mark`, which either sets a fixed number of resources to be sampled during an observation (positive integer value) or sets an observer to ''observe'' all resources in its `view` (0 or FALSE).
 - `times`, which sets how many times an observer will make observations during a time step (must be >0)
 - `samp_age`, which defines the minimum age at which resources are sampled (the default is set to 1, meaning that resources just added are not sampled -- could conceptualise this as sampling only adults; for now, it also makes the initial testing easier because carrying capacity has not yet been applied to juveniles during before observation -- can change this, of course.
 - `agent_type`, which identifies which agents are doing the observing. The default value is 0, which identifies the managers in the model. For most purposes, we will only need to have managers doing the observing, but there is definitely some utility in allowing other agents to do their own observing; more on this [below](#10-JAN-2017-other-obs).
 - `model`, which currently has to be "IBM". Eventually it might be nice to allow `observation.R` to shunt observations to something not individual-based, such as [Nilsen's model](#Nilsen), or another analytical equivalent, but not yet.
 
The file `observation.R` calls the function `observation` in the file `observation.c`. This c file follows the following general protocol:

The function `observation` is called, which does the following:

 - Reads the resource, landscape, and agent data arrays into c from R. It also reads in the parameter vector (which includes the optional inputs from the `observation.R` function).
 - Calls the function `mark_res` a total of `times` times -- each time simulating a unique trip to do field work. `mark_res` is a general function for marking individuals. Other functions can eventually be called instead of, or in addition to, `mark_res`, but the function is already very flexible, so it's hard to imagine what other function might be needed -- `mark_res` is currently the default and only function called. **Details on the function are [below](#function-mark-res)**.
 - builds a new array of observations `obs_array`. This array includes a row for every resource observed and all of the columns that also exist in the resource array (e.g., identifying resource location, identity number, types, life-history parameter values, etc.). Additionally, the observational array also includes a column for each `times` -- the number of times that observations are made. These columns hold values of 0 or 1, which indicate whether (1) or not (0) a resource was observed during a particular observation (can think of `times` as outings in the field, each producing a column of whether a resource was spotted/marked/recaptured or not).
 - Reads the `obs_array` into a format that can be returned to R
 
<a name="function-mark-res">The function</a> `mark_res` is called by `observation`, and does the following:

 - Identifies each observer in the agent array. Agents of a specified type (usually type 0) act as observers and thereby perform the observational tasks. By default, we assume that there is one agent of type 0 that acts as a lone manager (or, perhaps, a very cohesive team) who does all of the work, but if we have more type 0 agents, then each will do the same amount. For each type 0 agent, two functions are called in succession (recall that mark_res might be called multiple times in success by `observation`):
  - `field_work` causes the agent to go out and do some observational field work.
  - `a_mover` causes the agent to move according to some specified rules, as stored in the parameter vector and agent array. The default is simple uniform movement some Euclidean distance away after doing field work -- setting up for field work in a different location. The code is almost identical to the code that moves reources in `resource.c`, so I'll not explain this here.
  
The function `field_work` simulates the process of an agent looking for and tagging resources in some way (this can later be interpreted as viewing, tagging, marking, recapturing, etc.). There are currently two different tagging procedures possible (with the option to build more):

 1. Tag all resources within some Euclidean distance of the observer. The distance is determined by a parameter in the agent data frame. Resources within this distance are found using the `binos` function (simulating, e.g., binoculars).
 2. Randomly tag `fix_mark` resources on the landscape (*note: which resources is not a function of space*)

**After the observation function is run, we thereby have an obervational data frame in which rows are individual resources, and columns include traits of those resources (same as in the resource data frame) and whether or not the resource was observed during a particular simulated outing. Through a combination of specifications for `times` and `fix_mark` options, observational data frame can then be interpreted in multiple ways and used in a simulated analysis:**

There are multiple ways to interpret the observation results. Examples of this are as follows (for now, I'm assuming that there is one observer, but we can substitute the below with any number of observers):

 - Have the observer tag every resource within their range of vision some number of times; take the average of number of resources tagged per time as an estimate of population density.
 - Have the observer tag every resource within their range of vision some fixed number of times, but then interpret some of those times as *marks* and others as *recaptures*. Uneven times for marking and recapturing could be interpreted as different investment in each procedure (e.g., go out and mark at 3 different locations, then recapture at 9 locations). Unique marked and recaptured individuals can be summed to estimate population size using capture-mark-recapture techniques. Currently, there is some code in R simulating a [Lincoln-Petersen](https://en.wikipedia.org/wiki/Mark_and_recapture#Lincoln.E2.80.93Petersen_estimator) estimator of mark-recapture with a [Chapman correction](https://en.wikipedia.org/wiki/Mark_and_recapture#Chapman_estimator) for small sample size [see @Pollock2016]. It would be useful to add some other estimatores (e.g., Bayesian).
 - Have the observer sample a fixed number of resources on the landscape some number of times (*not spatial -- resources are just randomly taken*). Interpret one or more of these samples as markings, and one or more as recaptures. Then, use these data to estimate population size using some technique such as mark-recapture estimation. This is the technique used in the [figure](#u-10-JAN-2017) shown above.
 - Note, because observation arrays are stored by R, population size estimation can span multiple time steps (e.g., mark one year, recapture the next -- though some individuals might die in the intervening period)
 
 <a name="10-JAN-2017-cmr-details">Details</a> of the technique used to produce the above figure include the following:
 
 - One type 0 agent exists to do all of the observing.
 - A fixed sample of 20 resources are marked (if fewer than 20 sampled resources exist, then all resources are sampled -- this never happened though) at each time field work is done.
 - Field work is done 12 times in a time step, perhaps simulating 12 outings over a short time period within a calendar year.
 - Three of these outings are interpreted as periods of marking, where resources are tagged.
 - Nine of these outings are interpreted as periods of recapturing, where resources are caught and recorded.
 - Unique resources tagged by the agent in the first three and last nine outings are interpreted as unique marks and recaptures, respectively.
 - After all time steps are simulated, a function written in `gmse.R` figures out what the estimate of the population size would be for each time step. The analysis uses a very simple `chapman_est` function that I wrote in R. This function, or something like it, might be later incorporated as part of the observation model itself (likely by having observation.R call a different c file or R function), or in the manager model, or somewhere inbetween. I haven't decided.
 
For now, it's time to take another step back and take stock of what needs to be done next. A manager model and user model will need to start looking at multiple resources for making decisions, and somehow both potentially feed into a game-theoretic model. The complexity involved with the integration of management, games, and user actions should be a bit mitigated by all of these eventual functions revolving mostly around the agent array, with some input from the observation array. Of course, at least one type of agent will need access to the observational data as input (perhaps only to ignore it, sometimes), and users will need access to the resource array for off-take and other things. Some careful planning is needed for what happens next. I am particularly becoming aware that the flexibility of this model, while definitely a good thing, has the potential to tempt me into creating a lot of end user options that no one will actually want. **It might be a good idea to develop a list at some point separating key options that we definitely want to be visible to all end users from more obscure options that are available to us by editing the central gmse.R script.** It's also likely that a model of this scope will require a well written R function that translates different combinations of user-friendly inputs into an R list, which can then be interpreted by the script that calls `resource.R`, `observation.R`, `manager.R`, `game.R`, and `user.R`, and which places inputs into the vector `para` appropriately.

<a name="#10-JAN-2017-other-obs">It's worth noting</a> that the flexibility of the `observation` function might be used to address social questions that interest us. I've been mainly conceptualising the observation model as something done by a disinterested third party -- a manager rather than a stake-holder per se. The manager would make some decision that then affected payoffs in a game among stake-holders. We can do this of course, but we can also allow the stake-holders themselves to observe, perhaps less thoroughly and with more potential for bias (as we assume that they have less time and expertise). For example, we might imagine some stake-holders to estimate population size or change over time for themselves by observing all of the resources within a short distance around their location -- perhaps (incorrectly) biased by large population changes (e.g., way more geese around my location this year than last -- estimate a lot of total geese this year overall). These observations could feed into the game and user models.
 
Also -- and this might require some tweaking -- the flexibility of the type columns (type1, type2, type3) means that observing can be flexible too. We could allow each individual to observe, or groups of individuals of the same type to observe. **NEW:** *We can also specify the type of individuals doing the observing by any category, including individual ID*. This means that we can tell a specific agents (assuming they are represented by rows) to observe, or loop through the function with specific agents. The agent's type (or ID) is stored in the observation output, indicating which agent did the observing if data frames get amalgamated from looping the `observation` function.
 

> <a name="u-22-DEC-2016">Update: 22 DEC 2016</a>


As a quick update, I now have a working population model for G-MSE, and have reached the point where it will probably be better for me to take a step back and plan a bit, then work on other aspects of the full model rather than add more bells and whistles to the population sub-component. The development that I have done includes five files (happy to send these for the curious):

  1. gmse.R -- A master file that I'm currently using to call everything else
  
  2. landscape.R -- A file that constructs an $m \times n$ landscape (in the code, this is a simple 2D array, the elements of which can contain any real number). Currently, there is an option to make this landscape any size and randomly place any number of 'resources' onto it, if desired. In the past, I have used some [code](https://github.com/bradduthie/Duthie_and_Falcy_2013/blob/master/landscape.c) to produce autocorrelation of values on the landscape; if it suits us, I can rewrite this code (to improve the readability) for application to G-MSE. I also think it would be useful to have the option of reading in an image (i.e., a map) and converting it to an array to be used as the landscape (e.g., [JPG](http://stackoverflow.com/questions/25050974/how-to-convert-a-jpeg-to-an-image-matrix-in-r), [BMP](http://stackoverflow.com/questions/16787894/need-help-converting-a-bmp-image-to-a-matrix-in-r), [etc.](https://dahtah.github.io/imager/imager.html)) -- I suspect some stakeholders might find this especially useful, as it might help them see the applicability more clearly. Also, I've left hooks in the R file to allow eventual development of a non-spatial model.

  3. initialise.R -- A file that generates a single 'RESOURCE' array, which will hold everything that might be of value to stakeholders; this includes, most obviously, individuals in populations of conservation interest, but can also be used to respresent things like hunting licenses or crop plots. The idea is to have a data structure that provides maximum flexibility -- individuals can be represented as rows (or *sets* of rows) within the array, and their types and attributes can be indexed by column:
  
```{r, echo=FALSE}
IDs        <- seq(from = 1, to = 10, by = 1);
type_1     <- sample(x = 1:2, size = 10, replace = TRUE);
type_2     <- rep(x = 0, times = 10);
x_loc      <- sample(x = 1:20, size = 10, replace = TRUE);
y_loc      <- sample(x = 1:20, size = 10, replace = TRUE);
move       <- rep(x = 2, times = 10);
time       <- rep(x = 0, times = 10);
remov_pr   <- rep(x = 0.1, times = 10);
growth     <- rep(x = 1.1, times = 10);
offspr     <- rep(x = 0, times = 10); # None at init
age        <- rep(x = 0, times = 10); # Start age zero
resource   <- cbind(IDs, type_1, type_2, x_loc, y_loc, move, time, remov_pr, growth, offspr, age);
rownames(resource) <- c("res_1", "res_2", "res_3", "res_4", "res_5", "res_6", "res_7", "res_8", "res_9", "res_10");
print(resource);
```

  - Note that the first column is a unique index for the discrete resource -- it tags it over time and the age of the resource. The type columns (cols 2 and 3) can respresented anything; perhaps most usefully different types of resources that stake-holders might have interest in (e.g., harriers versus grouse, geese versus crop biomass, reindeer versus ticket sales), but also sub-types (e.g., individual sex) and even *individuals at a different scale*. For example, we might loosely define individuals as being represented by the index of type-1 instead of rows explicitly. In doing so, we can interpret the above table as having two individuals (1 and 2) with perhaps a shared presence at 7 (individual 1) and 3 (individual 2) different locations (cols x-loc and y-loc); hence the scale of individuals can be finer than array rows. Similarly, we could represent multiple individuals in a single row by having each row represent a group of individuals of type-1 or type-2, with the quantity of individuals being represented in a column to be defined later. The key point here is that **this structure of coding and abstract definition of 'resource' will maximise flexibility over how individuals are represented and modelled**; a key challenge will be knowing when to use what kind of structure. Note also that these columns are not (yet) set in stone, and we can add more as need be (I'm already tempted to add a third abstract 'type', though I'm not sure if it would ever be needed).
  
  4. resource.R -- This file has only one real job, and that is to read in the `RESOURCE` array, `LANDSCAPE` array, `PARAMETER` vector, and `MODEL TYPE` (currently only individual-based model, "IBM"), and then call the appropriate resource model. this intermediary R file allows us to be flexible in re-routing the whole G-MSE to different population models, if need be. We could even mix and match the extent to which components use simple equation-based modelling (e.g., as in [Nilsen's MSE](#Nilsen)), and which use the more computationally-intense agent-based simulation (though I really don't think computation time will be much of an issue, even with the agent-based model). Currently, all this R file is doing is calling the C code and the file resource.c -- or, more accurately, it is calling the compiled file resource.so, which allows R to link to C. 
  
  5. resource.c -- This is the file that does all of the heavy lifting in terms of simulating resources on a landscape; it is written in C to make the computation run (much) more quickly (probably by two orders of magntiude). The file includes several C functions, one of which links them all by running the resource() function, which reads in the `RESOURCE` and `LANDSCAPE` arrays, and a `PARAMATER` vector (containing any key parameter values) from R, and returns a new `RESOURCE` array (hence, landscape and parameter values are unchanged). A rough outline of what this key function does is as follows:
    - Reads and edits all of the key input into a form that C can store and use
    - Calls function `add_time`, which writes a time step and adds an age to all rows (see table above)
    - Calls function `mover` to move individuals some Euclidean distance according to a parameter (see above) and movement rules (currently: uniform probability of cell distances, Poisson probability of distances). This program also uses a parameter to determine what happens at the edge of the landscape -- currently, either nothing happens (i.e., individuals are just 'out of view') or the landscape wraps around as a torus (i.e., if you leave on the left side, you come back on the right).
    - Calls the functions `res_add` and `res_place` to simulate the addition of new resources (e.g., birth of individuals) and place them in a new array, respectively. Currently, old rows (e.g., individuals) directly create new rows according to a `growth` parameter (see table above), simulating birth, but this can be changed. A carrying capacity can also be applied to addition of new rows. New rows are also identical to their 'parent' rows in everything except ID and age, but this can also be changed.
    - Calls the function `remove` to remove some of the old rows from the input array -- currently removal of rows occurs with some fixed probability (`remov_pr`, see table above), or probabilistically based on a set carrying capacity. 
    - Combines the rows of the original `RESOURCE` array that were not removed with the newly created resources to make one single array (*might want to make this its own function later, for readability*).
    - Reads and edits all of the key output back into a form that can be recognised by R as a data frame.
    - **Note**: There is plenty of room for expanding this population model, and adding components such as immigration and emigration, interaction of resources, more complex movement, spatial heterogeneity of birth and death, sexual reproduction, disturbance, etc. This is just what I consider to be a minimal individual-based model useful for simulating a population. The code appears to be stable, though a bit more error checking would be useful, and some warnings need to be added to the code -- also, as of now, it is possible to have divergent growth of population size, maxing out the computer's memory and causing the program to crash. Some safeguard against this needs to be written in. 
    
A small script can help us see the output of what's going on in the population, both in terms of individual movement and change in population abundance over time. The run time of the below population is negligible -- all of the data underlying the 100 time steps shown in the figure below is produced in a tenth of a second (**4 JAN Update: Assuming instead a carrying capacity of 40000, closer to the ball-park of the Islay geese, 100 time steps takes 11 seconds**). The upper panel of the figure below shows a landscape (light and dark brown -- these colours don't mean anything at the moment, but could represent different landscape properties) with individuals (black) that move around, reproduce, and die in each time step. The lower panel shows the abundance of these individuals as they increase to carrying capacity (red dashed line), whereafter the population size remains stable (of course, simulating a bigger population takes a bit more time -- it takes about nine tenths of a second to simulate 100 time steps at a carrying capacity of 4000). 

![Image an example run of the population model](images/pop_model_eg.png)


<a name="intro">Towards a Game-theoretic Management Strategy Evaluation (G-MSE):</a>
================================================================================

I would like to develop one general, efficient, open-source, and user- and developer-friendly program for G-MSE that would be a general tool for applying game theory and management strategy evaluation to specific problems of conflict among stake-holders. I'm somewhat flexible on the development, but my preference would be to have software that is:

 - Open-source, with all version-controlled development history being publicly available on GitHub.
 
 - Written primarily or entirely in C (for efficiency and portability)
 
 - Easily called from R using an [R package](https://hilaryparker.com/2014/04/29/writing-an-r-package-from-scratch/) ([see also](http://r-pkgs.had.co.nz/description.html)) and appropriate R functions (as many scientists would likely want to integrate the program with other R packages and their own code or data). Note that this [could be tricky for windows users](https://b4winckler.wordpress.com/2012/04/14/r-package-c-code/). See details on the [most flexible](http://r-pkgs.had.co.nz/src.html) way to call R from C.
 
 - Usable with a browser-based GUI (or perhaps an app, though I'd have to learn how to do this), probably 'shiny' on top of R.
 
   - Useful for scientists or stake-holders unfamiliar with R, or command line code more generally

   - Perhaps useful as a teaching tool for students or the general public

   - Could look similar to this: < https://tomhopper.shinyapps.io/TB_Cases_shiny/ >, the code repository of which is availabile here: < https://github.com/tomhopper/TB_Cases_shiny >. Each tab could have a different set of related inputs and outputs, which together could produce a full report in the browser.

 - Comparable in scope to something like RangeShifter: http://rsdevs.github.io/RSwebsite/ [@Bocedi2014a]


<a name="gendev">General model development</a>
--------------------------------------------------------------------------------

**MAJOR POINTS: Some major points fleshed out given the thinking below:**

 - **The G-MSE model will focus on the dynamics of 2+ different objects**
 - **There will be 2+ stake-holders that each have an interest in the quantity of one or more objects**
 - **The 2+ different objects modelled will have some effect on one another**
 - **Effects of objects on one another will cause conflict (or cooperation) between stake-holders**

> **Question**: The *objects* (i.e., populations, resources, commodities) will often be represented as discrete entities (individual animals in populations, but also things like licenses sold and crop patches saved or raided -- which could have individual locations). Should the *stake-holders* also be modelled as (potentially multiple) discrete entities? This is easy to see if, e.g., stake-holders are potential hunters that do or do not buy licenses and engage in hunting, but maybe conservationists could also be considered as discrete -- each individually affecting the decision of an organisation in a game. 

**Given the question above**: Stake-holders could then also be represented by a data frame, which could generalise the model to allow many individual stake-holders to play a game (or not, if data frame is single row, or scalar). This could then more naturally incorporate mixed strategies (some will take one strategy, some another) and uncertainty. In the case that it is some sort of organisation making a decision, this would allow the individual stake-holders to collectively affect a single action or policy. This would appear to drift more into the realm of [agent-based computational economics](https://en.wikipedia.org/wiki/Agent-based_computational_economics), which might be a good thing given the goals of ConFooBio. This could allow for maximum flexibility too, if agents could also be discrete individuals making decisions.

**Should the model therefore be focused on at least four data frames modelling individuals? At least two modelling individual species or resources of interest (and at least one being a population of conservation interset), and at least two modelling modelling individuals with interests in the former?**

I think that the agent-based model is really going to be the default one to use, with other models being useful only if the end user is really tied to them in some way. In general, to find emergent phenomena and predict dynamics and decisions accurately, I think it will be useful to keep in mind the maxim of keeping situation rules simple while allowing agents to be complex ([Volker Grimm](https://www.ufz.de/index.php?en=36522) said something like this in one of his talks or publications, and given the ConFooBio focus, I think it's especially applicable).

Before getting into specifics, it will be useful to walk through the G-MSE model conceptually to figure out what kinds of approaches are going to be most useful for the following:

 1. Manager model
 2. User model
 3. Natural resources model
 4. Observation model
 5. Game-theoretic model
 
Each of these needs a general framework that will be most usefully applied to real-world problems of conflict. Ideally, these models will be modular -- i.e., not depend on the *type* of modelling being done in other areas of G-MSE. That way, we might, e.g., decide to substitute an entirely different kind of natural resources model (e.g., simple numerical Lotka-Volterra versus spatially explicit individual-based model), but still be able to generate input/output in each component to be used by the next.

Nevertheless, there needs to be some *conceptual* framework that is consistent, in addition to the five above modules. I've written down some of these ideas, deliberately avoiding Nilsen's [MSEtools](https://github.com/ErlendNilsen/MSEtools) repository for now. Some potential things that are common to G-MSE:

3. Population dynamics -- every case study, and indeed, every concievable application of G-MSE will include **at least two things that are dynamic**. In all of the case studies, at least one of these things is a population; sometimes the second is as well (e.g., hen harriers and grouse), but sometimes the second thing is a resource or commodity (e.g., crop biomass harvest, fishing licenses sold, etc.). I think that it is possible to generalise the model by tracking two *things* (loosely defined) over time with some sort of flexible structure (data frame, matrix, scalar). Different stake-holders will have an interest in one or both of these things. Change in these things over time might be dependent on previous time steps (as is expected for populations), or they might not be (as might be the case for fishing licenses sold). 

The model is therefore going to need to generally hold two or more variables or objects that represent populations or resources (including biomass) that can both be affected by any of the sub-components (*note:* even something like fishing licenses sold can be *oberved*, perhaps with trivial error -- we can therefore apply the same process of MSE to both populations and the things with which they are in conflict). 

In any case, there will be a need to model how properties of the population change from one time step to the next. Properties of interest for *populations* might include:

 - Population size
 - Population structure (age or stage classes)
 - Individual attributes (location, phenotype, etc.)

It would seem as though properties for conflicting resources would be more likely to boil down to one number (e.g., crop yield, licenses sold), but maybe not. We could, for example, assign a location to farms and licenses, or units of biomass in some way.

I think an individual-based model that represents individuals and resources with a table is probably the best way to go in most cases. We can perhaps broaden this out so that the observation model will recognise a table (IBM), a vector (classes), or a number (just size), with some indication of the type of data being returned, but most of the time a full table will be the way to go (*in fact, we could probably just make everything a data frame, and have $1 \times 1$ data frames be interpreted as scalar, and $1 \times n$ data frames be interpreted as a vector*). The information about the population will represent all of the relevant information about the natural population being modelled, so it can pass all of this information onto the observation model, which can then run some function to search through it and extract parameters of interest (with error, potentially). Within this model, we'll want functions to model birth, death, immigration, and emigration.

4. Observation -- Every application of G-MSE will include some type of sampling from the population dynamics model to extract statistics that are relevant to management. How exactly this sampling is done (and how it is modelled, perhaps, given diffent inputs from the population dynamics function) will vary with different techniques, but perhaps not so much. All observation samples a subset of the population (or some metric correlated with abundance -- e.g., dung or nest sites, which would be easy to represent). Therefore, there needs to be some sort of process for estimating the key parameters of interest (aforementioned population size, structure, attributes, etc.) from the complete table being inputted from the population dynamics part of the model. This could be something as simple as sampling from the full table:

 - With or without replacement
 - With bias to particular attributes
 - With error (false detection), including error in attributes (age, sex, etc.)

For scalar or vector inputs, observation error could be more directly simulated -- just with a parameter for bias and error (e.g., around population size, or sizes of each age or stage class). 

Alternatively, a different, more general way of doing it might be to instead simulate some length of time $t_{obs}$ for modelling the process of observation. Then each time step could include a probability of observing an individual. This might be even better because I think it would be more generalisable. In the case of the IBM, individuals could be observed following a Poisson process at each time step that:

 - Could recognise the same individual, or not
 - Could be biased to particular attributes (including location)
 - Include false detection probability at each time step

The benefit here is that a scalar or vector could be modelled in the same way, just by sampling from a Poisson distribution to find observation number at each time step of some number of individuals (potentially of different ages or classes). 


1. Management -- Here's where things get a bit more tricky, potentially. The management model will receive whatever the observation model produces, namely, two data frames representing the dynamic things of interest, typically:
 
 - Population with individuals conservation interest, where an IBM is being used (perhaps simulated with time stamps, locations, and individual attributes -- error in observations already produced), which will be most of the time.
 - Resource of interest, which might be interpreted by a manager, or not (if we're simulating a manager that is not concerned about the resource in question).

It will then spit out something that will affect both the game that agents play and therefore actions of users. 

One job of the management model will be to calculate statistics associated with the uncertainty surrounding these observations (e.g., confidence intervals), which will affect management decisions that are simulated.

> **TODO:** Need to figure out how management decions are going to be implemented. These deisions will feed directly into the game model, and possibly the user model.

5. Game model

This part is especially tricky. Need some common framework to convert the dynamic *things* (resource, population) into a utility function, then into a payoff matrix (or perhaps something even more general). Questions that need addressing before building the model:

 - Do we want the game to model more than two (types of) players?
 - Do we want the game to model more than two strategies per player?
 - Do we want the history of player actions to affect player strategies (i.e., extensive-form game versus a normal game)? If so, how complex are we willing to allow strategies to be?
 - How rational are we expecting individuals to be (do we want to solve Nash equilibria by default, or base behaviour on something else)?

We also want to include uncertainty in the games.


<a name="soft">General software development</a>
--------------------------------------------------------------------------------

The general structure of the program itself, I think, could fit into Figure 1 of [@Bunnefeld2011] (TREE paper), with a game-theoretic component added into the management model and harvester operating. Would game-theory among agents then be applied to the harvesters who are making decisions? A basic computational model would then proceed something like as follows:

********************************************************************************

**Master file: gmse.R [also create standalone gmse.c with int main(void)]**

 - Input all relevant variables, data.
 - Run seven functions; 2-6 forming an inner loop:
   1. initialise (initialise.c; start individuals, landscapes, etc)
   2. -> resource (resource.c; resource model, might burn in for a while first)
   3. -> observe (observe.c; observation model)
   4. -> manager (manager.c; management model)
   5. -> game (game.c; game theory applied, games played)
   6. -> user (user.c; actions take based game)
   7. summary (summary.R; extract and present information from data frames)
 - Exit program

**initialise.R: code within R to organise key data frames**

 - Switch(model_type):
 - case(agent_based):
    - Generate array `STAKEHOLDER_1` (*Stake-holders can be discrete*)
    - Generate array `STAKEHODLER_2` (*rows = individuals; cols = attributes*)
    - Generate array `RESOURCE_1` (*note: resources can be populations*)
    - Generate array `RESOURCE_2` (*rows = individuals; cols =  attribuets*)
    - Generate matrix `LANDSCAPE` (*start with an $m \times m$ matrix*)
 - case(matrix):
    - Generate matrices as appropriate
 - case(scalar):
    - Create variables as appropriate

**resources.c: sub-functions affect dynamics of resources**

 - Read `RESOURCE_1`, `RESOURCE_2`, and `LANDSCAPE`
 - Switch(model_type):
 - case(agent_based):
   - `move(double RESOURCE)`: move individuals or resources on LANDSCAPE
   - `reproduce(double RESOURCE)`: New resources added based on some rules
   - `die(double RESURCE)`: Resources removed based on some rules
   - `immigrate(double RESOURCE)`: resources added by different rules (later?)
   - `emgirate(double RESOURCE)`: resources removed by different rules (later?)
   - `interact(double RESOURCE_1, double RESOURCE_2)`: Resources interact
 - case(matrix):
   - To be developed later
 - case(scalar):
   - To be deveoped later
 - End with modified  `RESOURCE_1`, `RESOURCE_2`, and `LANDSCAPE`
 
**observe.c: sub functions affecting simulated data collection**

**manager.c: sub functions affecting management decision model**

**game.c: sub functions affecting game played based on management decisions**

**user.c: sub functions affecting implementation of users given game.c**

**summary.R: Summarise information and plot (also create C standalone)**

*Note*: The c standalone will also need the file gmse_util.c, for all of the other components (e.g., random number generation) which would normally be done in R. In R, these components can be incorporated with the appropriate R.h and Rmath.h header files.

*Note*: The `RESOURCE_2` will have to be optional, because in some scenarios, two stake-holders might simply be in conflict over the use of one resource.

********************************************************************************


**Note** that [Erlend Nilsen](https://github.com/ErlendNilsen) has constructed the basic MSE framework in R already, and I've [forked](https://github.com/bradduthie/MSEtools) his repository on GitHub as a potential starting point. I've also starred a [repository](https://github.com/cjgeyer/foo) for calling C from R, as I think that this will be necessary. I'd like a standalone version of the model in C, but the focus should probably first to be writing the intense code in C while immediately making it called from R -- cloning and making a C standalone can come later (maybe avoid using too much of Rmath.h so that a C standalone is easier).

This would allow a harvester operating module or function to fit within the broad simulation or program, G-MSE.

The spatial aspect of some of the key cases studies [e.g., @Nellemann2000], and the importance of space more broadly in ecological processes, suggests to me that the G-MSE program will need to ahve a spatial component -- landscapes need to be a part of it, perhaps?

Overall, based on the ERC proposal and @Bunnefeld2011, the model will function something like the below (subject to change):

```{r, echo=FALSE, fig.height=6.5, fig.width=3.8}
par(mar=c(0,0,0,0),mfrow=c(2,1));
plot(x=0, y=0, type="n", xlim=c(0,100), ylim=c(0,100), xaxt="n", yaxt="n",
     xlab="",ylab="");

# ------- G-MSE logo below:
text(x=0,y=97,pos=4,family="mono",labels="  ____       __  __ ____  _____ ");
text(x=0,y=90,pos=4,family="mono",labels=" / ___|     |  \\/  / ___|| ____|");
text(x=0,y=83,pos=4,family="mono",labels="| |  _ ____ | |\\/| \\___ \\|  _|  ");
text(x=0,y=76,pos=4,family="mono",labels="| |_| |____|| |  | |___) | |___ ");
text(x=0,y=69,pos=4,family="mono",labels=" \\____|     |_|  |_|____/|_____|");
lines(x=1:100,y=rep(99,100),lwd=3,col="red");
lines(x=1:100,y=rep(64,100),lwd=3,col="blue");
lines(x=rep(0,36),y=64:99,lwd=3,col="yellow");
lines(x=rep(100,36),y=99:64,lwd=3,col="orange");

polygon(x=c(rep(14,16),14:40,rep(40,16),40:14), # box
        y=c(40:55,rep(40,27),55:40,rep(55,27)),
        lwd=3,border="black");
text(x=27,y=50,labels="Long-term data", cex=0.65);
text(x=27,y=45,labels="input as CSV file", cex=0.65);

polygon(x=c(rep(45,16),45:90,rep(90,16),90:45), # box
        y=c(40:55,rep(40,46),55:40,rep(55,46)),
        lwd=3,border="black");
text(x=65,y=50,labels="Set key parameters using", cex=0.65);
text(x=65,y=45,labels="any of the below", cex=0.65);
arrows(x0=65, x1=1, y0=40, y1=31, lwd=2, length=0.00);
arrows(x0=65, x1=100, y0=40, y1=31, lwd=2, length=0.00);

polygon(x=c(rep(1,20),1:15,rep(15,20),15:1), # box
        y=c(11:30,rep(30,15),30:11,rep(11,15)),
        lwd=3,border="black");
text(x=8,y=25,labels="Browser", cex=0.65);
text(x=8,y=20,labels="Interface", cex=0.65);

polygon(x=c(rep(21,20),21:35,rep(35,20),35:21), # box
        y=c(11:30,rep(30,15),30:11,rep(11,15)),
        lwd=3,border="black");
text(x=28,y=25,labels="R", cex=0.65);
text(x=28,y=20,labels="Interface", cex=0.65);

polygon(x=c(rep(41,20),41:100,rep(100,20),100:41), # box
        y=c(11:30,rep(30,60),30:11,rep(11,60)),
        lwd=3,border="black");
text(x=68,y=25,labels="Main C file: contains int main()", cex=0.65);
text(x=68,y=20,labels="Calls model; can relay to R", cex=0.65);

arrows(x0=15, x1=20, y0=20, y1=20, lwd=2, length=0.08);
arrows(x0=35, x1=41, y0=20, y1=20, lwd=2, length=0.08);
arrows(x0=68, x1=1, y0=11, y1=2, lwd=2, length=0.00);
arrows(x0=65, x1=100, y0=11, y1=2, lwd=2, length=0.00);

text(x=56, y=0, cex=0.60,
     labels="(Use long-term data in Natural Resource Model before MSE)"
     );

# ===============================================================
plot(x=0, y=0, type="n", xlim=c(0,100), ylim=c(0,100), xaxt="n", yaxt="n",
     xlab="",ylab="");
# Manager model box
polygon(x=c(rep(1,30),1:30,rep(30,30),30:1), # box
        y=c(70:99,rep(99,30),99:70,rep(70,30)),
        lwd=3,border="red");
# User model box
polygon(x=c(rep(70,30),70:99,rep(99,30),99:70), # box
        y=c(70:99,rep(99,30),99:70,rep(70,30)),
        lwd=3,border="orange");
# Obeservation model box
polygon(x=c(rep(1,30),1:30,rep(30,30),30:1), # box
        y=c(1:30,rep(30,30),30:1,rep(1,30)),
        lwd=3,border="yellow");
# Natural resources model
polygon(x=c(rep(70,30),70:99,rep(99,30),99:70), # box
        y=c(1:30,rep(30,30),30:1,rep(1,30)),
        lwd=3,border="blue");
# Natural resources model
polygon(x=c(rep(36,30),36:65,rep(65,30),65:36), # box
        y=c(36:65,rep(65,30),65:36,rep(36,30)),
        lwd=3,border="green");
arrows(x0=15, x1=15, y0=30, y1=70, lwd=2, length=0.15);
arrows(x0=30, x1=70, y0=85, y1=85, lwd=2, length=0.15);
arrows(x0=85, x1=85, y0=70, y1=30, lwd=2, length=0.15);
arrows(x0=70, x1=30, y0=15, y1=15, lwd=2, length=0.15);
arrows(x0=30, x1=36, y0=70, y1=65, lwd=2, length=0.075, code=3);
arrows(x0=65, x1=70, y0=65, y1=70, lwd=2, length=0.075, code=3);
text(x=50, y=90, labels="Policy");
text(x=50, y=20, labels="Monitoring");
text(x=10, y=48, labels="Indicators", srt=90);
text(x=90, y=52, labels="Off-take", srt=-90);
text(x=50, y=70, labels="Bayesian Priors", cex=0.8);
# Manager model details: 
text(x=15, y=95, cex=0.75,labels="Manager model");
text(x=15, y=90, cex=0.75,labels="file: manager.c");
text(x=15, y=85, cex=0.75,labels="In: Obs. Data");
text(x=15, y=80, cex=0.75,labels="Out: Game para.");
# Bayesion priors details: 
text(x=50, y=60, cex=0.75,labels="Bayesion Game");
text(x=50, y=55, cex=0.75,labels="Theory model");
text(x=50, y=50, cex=0.75,labels="file: game.c");
text(x=50, y=45, cex=0.75,labels="In: Game para.");
text(x=50, y=40, cex=0.75,labels="Out: Payoffs");
# Manager model details: 
text(x=85, y=95, cex=0.75,labels="User model");
text(x=85, y=90, cex=0.75,labels="file: user.c");
text(x=85, y=85, cex=0.75,labels="In: Payoff");
text(x=85, y=80, cex=0.75,labels="In: Obs. Data");
text(x=85, y=75, cex=0.75,labels="Out: Off-take");
# Natural resources model details: 
text(x=85, y=25, cex=0.75,labels="Natural");
text(x=85, y=20, cex=0.75,labels="resources model");
text(x=85, y=15, cex=0.75,labels="file: resources.c");
text(x=85, y=10, cex=0.75,labels="In: Off-take");
text(x=85, y=5, cex=0.75,labels="Out: Pop. Dyna.");
# Natural resources model details: 
text(x=15, y=25, cex=0.75,labels="Observ. model");
text(x=15, y=20, cex=0.75,labels="file: observe.c");
text(x=15, y=15, cex=0.75,labels="In: Pop. Dyna");
text(x=15, y=10, cex=0.75,labels="Out: Obs. Data");

```

 
As long as not too many generations are run (e.g., not too much more than 100), I am *cautiously* optimistic that this program will be able to include an individual-based model of a focal population, and all of the other game-theoretic components, and not take more than a few minutes to run and produce simulated results (obviously less if it is called directly from C, but I'm shooting for this calling from shiny in a browser). For end users, dynamic graph production can make the wait time a bit more interesting, if it's possible. For us, the time it will take for me to call in c, especially if using a the cluster, will be trivial.

For the **natural resources model**, it might be nice to have an option of burning in several time steps before starting the loop (if, e.g., no empirical data are available, and the model instead relies on parameters plugged into a Lotka-Volterra or Ricker model). Or, if data are available, long-term demographic data could be used and assumed to represent the *true* population dynamics (i.e., just use these data to simulate *N* individuals) before starting the G-MSE model loop. It is worth thinking about how much population structure we might want to add -- my inclination is to make the software as flexible as possible (e.g., allow sex, age, etc., to be attributes of discrete individuals), but this will depend on other aspects of the model.

<a name="game">Game-theory modelling (game.c; green box above)</a>
--------------------------------------------------------------------------------

In the interest of making this model as general as possible, I believe that we'll eventually want to use an [extensive-form game]([https://en.wikipedia.org/wiki/Extensive-form_game) to allow for the sequence of moves to affect stake-holder actions. Nevertheless, just to get the basic framework underway, I think we can start out with a [normal-form game](https://en.wikipedia.org/wiki/Normal-form_game), with the intent of generalising the model later (the code will be modular enough to allow this). Generalisation should be easy if we have a separate function to keep track of the [game tree](https://en.wikipedia.org/wiki/Game_tree), and then allow agents to access the game tree (or parts of it, in the case of incomplete information) to make decisions about how to act. An extensive-form game package exists in R, published by @Kenkel2014 with [code](https://github.com/brentonk/games) available on GitHub, but the focus of this package is for 'estimating recursive, sequential games, and not simultaneous move games or dynamic games with infinite time horizons'. Since the quoted probably describes the kinds of games that ConFooBio is interested in, I think the games package will be a useful reference, but not something to directly apply. It incorporates uncertainty, which could be something useful to return to for further reference.

A couple other (Java based) examples of games are available on GitHub, such as [GTE](https://github.com/gambitproject/gte), which has a [GUI](http://gte.csc.liv.ac.uk/gte/builder/) web application and a corresponding published paper [@Savani2014]. This model leads me to think that it's probably best to give each player two matrices: 

 1. A payoff matrix representing different player actions and payoffs 
  - payoffs are defined by utility functions for each player.
  - These could be represented by a three dimensional array, or a list (list would allow the `do.call` function to be used -- probably easier to deal with in R).
 2. A history matrix showing the results of previous interactions; note that giving each player their own history matrix will allow players to have incomplete (or perhaps incorrect) information about the game. 
 
Another java extensive-form games [package](https://github.com/ChrKroer/ExtensiveFormGames) exists, though it seems like less useful for ConFooBio purposes.

**Some notation to try out:** For the purpose of the below, to keep things simple, I'm going to just start with payoff matrices, and assume that history of interactions is not yet used in decisions.

- Denote $U^{m}_{k}$ as the utility to agent $m$ ($m \in \{1, ..., M\}$) from the outcome $k$.
- The probability that $m$ chooses an action $X_{i}$ from all possible options $i \in I$ can be represented as $p^{m}_{i}$.
- The action for $m$ can be represented $X^{m}_{i}$, so $E[X^{m}_{i}] = \int_{I} x^{m}_{i} f(x^{m}_{i})dx$. Or something like it.
- Hence we can write $U_{m,k}(X^{m}_{i})$ for all $m$, which defines the payoff, as affected by the actions of $m$ and other players.

To further simplify, I am going to assume that there are only two players. The general payoff matrices can be represented as below (loosely following the notation of @Debarre2014):

$$
{\bf A^{1}} = \left( \begin{array}{cc}
    U^{1}_{a} & U^{1}_{b} \\
    U^{1}_{c} & U^{1}_{d} \end{array} \right), 
{\bf A^{2}} = \left( \begin{array}{cc}
    U^{2}_{a} & U^{2}_{b} \\
    U^{2}_{c} & U^{2}_{d} \end{array} \right).
$$

In the above $a$, $b$, $c$, and $d$ are all different possible outcomes that depend upon the decisions of players 1 and 2. We can think about these in terms of the actions $X^{1}_{i}$ and $X^{2}_{i}$, and put these into the familiar payoff table below,

|              | **Player 2**               |                            |
|--------------|----------------------------|----------------------------| 
| **Player 1** | Strategy 3                 | Strategy 4                 |
| Strategy 1   | $a \to \{U^{1}, U^{2}\}$   | $b \to \{U^{1}, U^{2}\}$   |
| Strategy 2   | $c \to \{U^{1}, U^{2}\}$   | $d \to \{U^{1}, U^{2}\}$   |

For doing the maths though, individual matrices will be used. Note that to keep things general, the above strategies are unique to each player. I think that this will be relevant to ConFooBio because each actor will have a unique role. Hence, a vector $I$ can represent all possible options for action, with players (normally) only having access to a subset $i \in I$, though we might conceive of some players being able to do the same thing despite having different roles. 

Making payoff matrices a list with $M$ elements of vectors is probably the best way to go in R, with $M=2$ players for most of what we'll do. Each player $m$ will have its own options for acting within the list `M[m]`.

```{r}
M     <- 2; # Number of players in the game
S     <- list(); # Strategy vectors (elements all possible strategies)
A     <- list(); # Payoff vectors (elements all possible strategy combinations)
```

For now, let's just assume that each player has two possible strategies, and we'll just use the traditional matrix to calculate Nash equilibria; for future reference, @Avis2009 might be useful for quick calculation of Nash equilibria for two player games. Continuing with the above, here's a basic setup computing the Prisoner's dilemma:

```{r}
S[[1]] <- c("C","D"); # Cooperate or defect strategies (change to numeric?);
S[[2]] <- c("C","D");
A[[1]] <- c(3,0,5,1); # Payoffs for player 1
A[[2]] <- c(3,5,0,1); # Payoffs for player 2
A1     <- matrix(data=A[[1]], nrow=length(S[[1]]), byrow=FALSE); 
A2     <- matrix(data=A[[2]], nrow=length(S[[2]]), byrow=FALSE); 
print(A1); # Note the traditional Prisoner's dilemma payoff structure
print(A2);
```

Now check to see if the best possible response for each player is the same regardless of its opponent's strategy.

```{r}
best1 <- apply(A1,1,which.max); # Best strategies for Player 1
best2 <- apply(A2,2,which.max); # Best strategies for Player 2
tabl1 <- tabulate(best1); # Frequency of bests
tabl2 <- tabulate(best2); 
str1  <- tabl1 / sum(tabl1); # Frequency of each strategy
str2  <- tabl2 / sum(tabl2);
summ1 <- matrix(data=str1,nrow=1); # Summary vector of strategies
summ2 <- matrix(data=str2,nrow=1);
colnames(summ1) <- S[[1]];
colnames(summ2) <- S[[2]];
rownames(summ1) <- "Proportion";
rownames(summ2) <- "Proportion";
print(summ1); print(summ2);
```

One goal will be to develop a function that can return optimal strategies for each player, including mixed strategies, for any given $2 \times 2$ payoff matrix. The function below does not do this; it needs to be fixed. A starting point for looking at appropriate algorithms is @Avis2009, who come up with an efficient solution.

**Before investing too much time in this, let's make sure that finding equilibrium solutions make sense in the context of games with uncertainty. We might need a different approach, e.g., if the payoffs themselves are uncertain and the optimal strategies are reflected in this uncertainty**

One [package](https://github.com/cran/GNE) in R can solve Nash equilibria, though the documentation for it is not excellent. There's also a [repository](https://github.com/hphoellwirth/qpne-2016) that can do it in C, but that might take more time than it is worth -- the paper underlying it is @Miltersen2009. A benefit here is that it uses extensive-form games and computes [*quasi-perfect equilibria*](https://en.wikipedia.org/wiki/Quasi-perfect_equilibrium), which are specifically equilibria that assumes that a player's opponent is not perfect, and accounts for past mistakes.

```{r}
## XXX FIXIT: There is an error in calculating what each should play -- it is tabulating the frequency of best plays, but when mixed strategies occur, it returns a 1/2, 1/2 instead of the proportion based on the value. 
solve.nash <- function(){ #Function to be made to solve Nash equilibrium
   return(NULL);
}


game <- function(payoff1, payoff2){
    if(length(payoff1) != length(payoff2)){
      print("WARNING: Payoff vectors must be the same length");   
      return(NULL);
    }
    if(min(payoff1) < 0){
      payoff1 <- payoff1 + min(payoff1);   
    }
    if(min(payoff2) < 0){
      payoff2 <- payoff2 + min(payoff2);   
    }    
    if(is.matrix(payoff1)==FALSE){
      payoff1 <- matrix(data=payoff1, nrow=2, byrow=TRUE);   
    }
    if(is.matrix(payoff2)==FALSE){
      payoff2 <- matrix(data=payoff2, nrow=2, byrow=TRUE);   
    }
    S      <- list(); 
    S[[1]] <- c("Strategy_1","Strategy_2"); 
    S[[2]] <- c("Strategy_3","Strategy_4");
    best1  <- apply(payoff1,1,which.max); # Best strategies for Player 1
    best2  <- apply(payoff2,2,which.max); # Best strategies for Player 2
    tabl1  <- tabulate(best1); # Frequency of bests
    tabl2  <- tabulate(best2);
    expe1  <- apply(payoff1,2,sum) * tabl1;
    expe2  <- apply(payoff2,1,sum) * tabl2;
    str1   <- expe1 / sum(expe1); # Frequency of each strategy
    str2   <- expe2 / sum(expe2);
    summ1  <- matrix(data=str1,nrow=1); # Summary vector of strategies
    summ2  <- matrix(data=str2,nrow=1);
    colnames(summ1) <- S[[1]];
    colnames(summ2) <- S[[2]];
    rownames(summ1) <- "Proportion";
    rownames(summ2) <- "Proportion";
    strategy_pr     <- list(player1=summ1,player2=summ2);
    return(strategy_pr);
}
```

We can now use the function above to figure out and return strategies for any given payoff vectors from $a$, $b$, $c$, and $d$ for each player (1 and 2).

```{r}
u <- shinyUI(pageWithSidebar(

  headerPanel(""),
  sidebarPanel(
    textInput('vec1', 'Player 1: a, b, c, d', "3, 5, 0, 1"),
    textInput('vec2', 'Player 2: a, b, c, d', "3, 0, 5, 1")
  ),

  mainPanel(
    h4('Proportion strategy is optimally played: (DOES NOT WORK YET)'),
    verbatimTextOutput("oid1")
  )
))

s <- shinyServer(function(input, output) {

  output$oid1<-renderPrint({
    p1  <- as.numeric(unlist(strsplit(input$vec1,",")))
    p2  <- as.numeric(unlist(strsplit(input$vec2,",")))
    pay <- game(payoff1=p1, payoff2=p2)
    o1  <- as.numeric(pay$player1)
    o2  <- as.numeric(pay$player2)
    cat("Player 1 (Strategy 1, 2):\n")
    print(o1)
    cat("\n\n")
    cat("Player 2 (Strategy 3, 4):\n")
    print(o2)
  }
  )


}
)
#shinyApp(ui = u, server = s)
```


<a name="gamemod">Game theory and modelling</a>
================================================================================

- How do we quantify costs and benefits in situations in which there is conflict between conservation and food security? Game theoretic models rely on numeric values being maximised by individual agents, with games promoting cooperation or conflict depending on equilibrium solutions when each agent maximises its value. But for conservation and food security, the values do not seem to be straightforwardly assigned -- how do we compare something like extinction risk against food production (or, e.g., tourism income)? It seems that we need to either figure out how to play games in which payoffs are in different, difficult-to-compare currencies, or figure out how to standardise disparate payoff types into a common currency to model games. 

 - **Note that there is a whole literature surrounding utility and utility functions, most of which appears to be based in economics.** This is probably the best thing to tap into, although the question of what kind of utility functions to use (e.g., ordinal, continuous, etc.) is still something that will need to be worked out.

 - Could figure out some sort of way to rank order or bin preferences for each agent (*Added note: this might link up with Jeremy's idea of attitude in some way?*). This might also help with dealing with uncertainty because the uncertaintly of outcomes could be expressed as the likelihood or probability of hitting a rank or getting into a bin. Successful cooperation could then be defined by increasing, or perhaps maximising, ranks or bins of each agent. I had a actually played around with an idea for using something like this in philosophy (ethics theory), in which 'maximise well-being' is sometimes considered a fundamental concept, but one that is hard to pin down (i.e., could have links to environmental ethics). As a bonus, the ranks or bins could be easier for real-world agents to understand.
 
 - In any case, a game-theoretic model will need some sort of numbers to work with (even if they are just ordinal preferences), so I think this will be a key question early on.

- Should we have tables, such as the hypothetical one below? This is the typical way that games are modelled, but it assumes that different agents are playing the same game. If there are conflicts among more than two types of agents (i.e., agents with three or more unique interests), then fitting games into two-by-two boxes could be difficult (this was mentioned in the project proposal). 


|             | **Agent 2**     |                |
|-------------|-----------------|----------------| 
| **Agent 1** | Strategy 1      | Strategy 2     |
| Strategy 1  | A1 pay, A2 pay  | A1 pay, A2 pay |
| Strategy 2  | A1 pay, A2 pay  | A1 pay, A2 pay |


- I also think it is important to recognise early on that these games are unlikely to be symmetrical -- the payoffs are unlikely to be the kinds of simple prisoners dilemmas that lead to both agents having the same effective strategy [see also @Colyvan2011].

 - Note, I don't think that this means that simple Nash equilibria are impossible to find -- the solutions might just look a bit odd, depending on the payoff values in the matrices.
 
 - We should not, however, overlook the possibility of solutions that are optimally cooperative when played iteratively but not cooperative when played once. Prisoner's dilemma is the classic example; see the Axelrod experiments and @Wilkinson1990, @Carter2013, @Carter2015, @Trivers1985 work on reciprocal allocation. @Dawkins1976 also had a chapter on this, I think.
 
 - Given the above, we should also, perhaps, consider that payoffs might change over time (e.g., one year to the next) with changing environmental conditions (defined very loosely as anything outside of the agent's control that structures the payoff matrix), and that agents might capitalise on this stochasticity to maximise net gains. Further, they might change in a non-linear way such that one way of maximising payoffs is to let one agent 'win' in one year and another agent 'win' in the next year. This could benefit all if the payout in a given year has a huge benefit for the 'winner', but not an abnormally large loss for the 'loser' (probably should use different terminology than 'winner' and 'loser'); in subsequent years then, the other agent might find themselves in a situation where they have an abnormally high amount to gain from 'winning' and the other agent does not have an unusually bad year by 'losing'. Note that, I think, this implies that the changing payoff structure of a game over time might be dynamic in a way that is not purely a zero-sum situation; i.e., gains are non-additive (in the previous example 'sub-additive') over time. Non-additivity could work the opposite way too -- it might be that when it is unusually good time to 'win', it is an even worse time for the other agent to 'lose' -- I'd need to flesh out this idea more; it has conceptual connections to the community ecology (species interactions) literature.
 
 - As a concrete example of the above -- maybe, e.g., the conditions are particularly good for hen harrier conservation in the current year (i.e., a population is poised to grow especially well, or rebound in some critical way) -- so good that maximising gains now would well compensate for the expected losses if grouse hunters enforced control in the subsequent few years. Perhaps banking these conservations gains would be the best solution, if at a later date the conditions would be such as to cause grouse hunters to benefit disproportionately from target control at a time in which the losses of control to conservation would not be especially severe. The net result of all this could be that each agent benefits by maximising its gains when times are tough at the cost of suffering higher losses when times are good. Again, this depends on variation in the payoff structure over time, and that the payoffs will vary in such a way as to cause sub-additive growth in gains. It also might require more certainty about gains that is reasonable.

- Need to think about uncertainty more.

<a name="Nilsen">Notes regarding Nilsen's MSE</a>
--------------------------------------------------------------------------------

The following recreates [Nilsen's MSE](https://github.com/ErlendNilsen/MSEtools) modelling work.

```{r, echo=FALSE}
PopMod1 <- function(X_t0=100, sigma2_e=0.2, N_Harv=20, K=200, theta=1, r_max=1.0){
  eps <- rnorm(1, mean=0, sd=sqrt(sigma2_e))
  X_star <- X_t0-N_Harv
  r <- (r_max*(1-(X_star/K)^theta))+eps
  X_t1 <- X_star*exp(r)
  PopRes <- as.data.frame(matrix(ncol=4, nrow=1))
  PopRes[1,1] <- eps
  PopRes[1,2] <- X_star
  PopRes[1,3] <- r
  PopRes[1,4] <- X_t1
  colnames(PopRes) <- c("eps", "X_star", "r", "X_t1")
  PopRes
}

obs_mod1 <- function(scale="Abund", value=1000, bias=1, cv=0.2, LogNorm="ND"){
  obs1 <-  switch(LogNorm,
                  LND={rlnorm(n=1, meanlog=log(value*bias), sdlog=cv)},
                  ND={rnorm(n=1,mean=value*bias, sd=cv*value)})
  obs1 <- switch(scale,
                 Abund={round(obs1)},
                 Dens={obs1})
  obs1
}


HarvDec1 <- function(HD_type="A", c=1000, qu=0.2, PopState_est=100){
  TAC <- switch(HD_type,
                A={PopState_est*qu},
                B={ifelse(PopState_est>c, PopState_est-c, 0)},
                C={qu},
                D={ifelse(PopState_est>c, qu(PopState_est-c), 0)})
  TAC
}

Impl1 <- function(TAC=10, ModType="A", p=0.7){
  H_I <- switch(ModType,
                A={rbinom(1, size=TAC, p=p)},
                B=(rpois(n=1, lambda=TAC*p)))
  H_I
}

```

 - In the **population models**, the harvest occurs before population grows in a given time step.
 - Four **population models** are included, all numerical models with no population structure and identical parameter inputs of initial population size, environmental stochasticity, harvest amount (raw number), carrying capacity, and max growth rate.
 - The **observation model** is the simplest possible model, taking in the population model data and returning an estimate with some error associated with the coefficient of variation of monitoring around the real abundance/density and some degree of bias.
 - The **manager model** (called the *Harvest Decision Model*) includes three types of management decisions:
  1. Proportional harvest
  2. Constant quota
  3. Threshold harvest
  
 - The **manager model** receives the single estimate of population size (density or abundance), then returns a total allowable catch. A second function models hunter frustration, and is meant to be run after the first function. The second function checks to see if hunter frustration is within a set of bounds; if it is, then the function returns the original total allowable catch. If it is not, then the function adjust the total allowable catch.
 
 - The **user model** (called the *implementation model*) includes four separate functions, including the very simple, which just samples from a random binomial or poisson function around total allowable catch.

**Hence, we can put four of these functions together to simulate a very simple MSE model:**

```{r}
pop_abund      <- 100;
harvest        <- 20;
growth_rate    <- 1;
K              <- 200;
pr_harvest     <- 0.7;

time           <- 1;
time_end       <- 30;
track          <- matrix(data=0, nrow=time_end, ncol=5);

while(time <= time_end){
    pop_vars     <- PopMod1(X_t0=pop_abund, sigma2_e=0.2, N_Harv=harvest, K=K, 
                            r_max = growth_rate);
    pop_abund    <- as.numeric(pop_vars[4]);
    obs_vars     <- obs_mod1(scale="Abund", value=pop_abund, bias=1, cv=0.4);
    if(obs_vars < 0){  # Nilsen's model allows estimate to be negative
        obs_vars <- 0; # Make it so that negative equates to est. of extinction  
    }
    har_vars     <- HarvDec1(HD_type="A", qu=0.2, PopState_est=obs_vars);
    imp_vars     <- Impl1(TAC=floor(har_vars), ModType="B", p=pr_harvest);
    track[time,] <- c(time, pop_abund, obs_vars, har_vars, imp_vars);
    time         <- time + 1;
}
colnames(track)  <- c("time", "Pop. Size", "Pop. Est.", "Harv. Rate", "Harv.");
```

We run the above code, and we can look at how key population and management quantities change over time:

  1. Population size (panel A; solid line)
  2. Population estimate size (panel A; dashed line)
  3. Harvest rate set by manager (panel B; solid line)
  4. Harvested number of animals (panel B; dashed line)
 
The below figure shows all of these quantities over time.

```{r, echo=FALSE, fig.height=6, fig.width=8}
par(mfrow=c(2,1), mar=c(0.25,5,4,1));
plot(x=track[,1], y=track[,2], xlab="", ylab="Pop. Abundance", lwd=2,
     col="black", ylim = c(0,max(track[,2:3])+85), type="l", xaxt="n",
     cex.lab=1.5, cex.axis=1.25);
points(x=track[,1], y=track[,3], col="red", lwd=2, type="l");
legend(x=2.5, y=max(track[,2:3]+85), horiz=TRUE,
       legend=c("Actual", "Estimate"), fill=c("black","red"));
par(mar=c(4,5,0.25,1));
plot(x=track[,1], y=track[,4], xlab="Time", ylab="Harvest", lwd=2, cex.lab=1.5,
     col="black", ylim = c(0,max(track[,4:5])+15), type="l", cex.axis=1.25);
points(x=track[,1], y=track[,5], col="red", lwd=2, type="l");
legend(x=2.5, y=max(track[,4:5]+15), horiz=TRUE,
       legend=c("Set", "Removed"), fill=c("black","red"));
```

We can re-run the code at any point and essentially recreate a run of [Nilsen's MSE](https://github.com/ErlendNilsen/MSEtools) model. The hard work is now to come up with a G-MSE, which will allow for much more individual complexity through an agent-based approach.


<a name="side">Some side-notes that might be of use</a>
--------------------------------------------------------------------------------

The [function](https://stat.ethz.ch/R-manual/R-patched/library/base/html/do.call.html) `do.call` in R [apparently](https://www.stat.berkeley.edu/~s133/Docall.html) calls a function and passes the arguments for the function from a list (e.g., if `A` is in a list form, or put in a list form with `list(A)`, then `do.call("f", list(A))` calls the function `f` for every list element in `A`, where individual list elements can be vectors with function arguments). This is a base R function.


<a name="meetings">Potentially relevant conferences and workshops</a>
--------------------------------------------------------------------------------

**Scottish Ecology, Environment, and Conservation Conference**
(''The conference aims to bring together researchers in ecology, conservation, and environmental sciences across Scotland'' -- **''The conference is primarily for PhD, Masters and advanced undergraduate students''**)
University of Aberdeen: 3-4 APR 2017
6 FEB abstract submission deadline

**Modelling Biological Evolution 2017: Developing Novel Approaches**
(topics include: Evolutionary Game Theory and Solving Social Dilemmas)
http://www.math.le.ac.uk/people/ag153/homepage/MBE_2017/MBE_2017_1.htm
University of Leicester: 4-5 APR 2017
1 FEB 2017 register and abstract submission deadline.

**Workshop on behavioural game theory**
(topic is Pyschological Game Theory)
https://www.uea.ac.uk/economics/news-and-events/workshop-on-behavioural-game-theory-2017
University of East Anglia (Norwich): 5-6 JUL 2017
28 FEB 2017 submission deadline (no workshop fee)

**Game theory and management**
(topics include: Game theory and management applications, cooperative games and 
applications, dynamic games and applications, stochastic games and appications)
http://gsom.spbu.ru/en/gsom/research/conferences/gtm/
Saint Petersburg University: 28-30 JUN 2017

**6th workshop on stochastic methods in game theory**
( ''Many decision problems involve elements of uncertainty and of strategy. Most often the two elements cannot be easily disentangled. The aim of this workshop is to examine several aspects of the interaction between strategy and stochastics. Various game theoretic models will be presented, where stochastic elements are particularly relevant either in the formulation of the model itself or in the computation of its solutions.'' Example topics include: Large games and stochastic and dynamic games)
https://sites.google.com/site/ericegametheory2017/home
Sicily, Italy: 5-13 MAY 2017

**13 European Meeting on Game Theory (SING13)**
(topics include: cooperative games and their applications, dynamic games, stochastic games, learning and experimentation in games, computational game theory, game theory applications in fields such as management).
http://www.lamsade.dauphine.fr/sing13/
Paris, France: 5-7 JUL 2017
28 FEB abstract submission deadline


<a name="ref">References consulted and annotated (Mendeley)</a>
-----------------------------------------

An, L. (2012). Modeling human decisions in coupled human and natural systems: Review of agent-based models. Ecological Modelling, 229, 25–36. https://doi.org/10.1016/j.ecolmodel.2011.07.010

Adami, C., Schossau, J., & Hintze, A. (2016). Evolutionary game theory using agent-based methods. Physics of Life Reviews, 19, 1–26. https://doi.org/10.1016/j.plrev.2016.08.015

Ascough, J. C., Maier, H. R., Ravalico, J. K., & Strudley, M. W. (2008). Future research challenges for incorporation of uncertainty in environmental and ecological decision-making. Ecological Modelling, 219(3–4), 383–399. https://doi.org/10.1016/j.ecolmodel.2008.07.015

Bautista, C., Naves, J., Revilla, E., Fernández, N., Albrecht, J., Scharf, A. K., ... Selva, N. (2016). Patterns and correlates of claims for brown bear damage on a continental scale. Journal of Applied Ecology. http://doi.org/10.1111/1365-2664.12708

Bennett, E. M. (2017). Changing the agriculture and environment conversation. Nature Ecology and Evolution, 1(January), 1-2. https://doi.org/10.1038/s41559-016-0018

Bischof, R., Nilsen, E. B., Brøseth, H., Männil, P., Ozoliņš, J., & Linnell, J. D. C. (2012). Implementation uncertainty when using recreational hunting to manage carnivores. Journal of Applied Ecology, 49(4), 824–832. https://doi.org/10.1111/j.1365-2664.2012.02167.x

Bjerketvedt, D. K., Reimers, E., Parker, H., & Borgstrøm, R. (2014). The Hardangervidda wild reindeer herd: a problematic management history. Rangifer, 34(1), 57–72.

Bonabeau, E. (2002). Agent-based modeling: methods and techniques for simulating human systems. Proceedings of the National Academy of Sciences, 99, 7280–7287. https://doi.org/10.1073/pnas.082080899

Bunnefeld, N., & Keane, A. (2014). Managing wildlife for ecological, socioeconomic, and evolutionary sustainability. Proceedings of the National Academy of Sciences, 111(36), 12964–12965. http://doi.org/10.1073/pnas.1413571111

Bunnefeld, N., Hoshino, E., & Milner-Gulland, E. J. (2011). Management strategy evaluation: A powerful tool for conservation? Trends in Ecology and Evolution, 26(9), 441–447. http://doi.org/10.1016/j.tree.2011.05.003

Chollett, I., Garavelli, L., O’Farrell, S., Cherubin, L., Matthews, T. R., Mumby, P. J., & Box, S. J. (2016). A Genuine Win-Win: Resolving the ``Conserve or Catch’’ Conflict in Marine Reserve Network Design. Conservation Letters, 0(0), 1–9. https://doi.org/10.1111/conl.12318

Cobano, J. A., Conde, R., Alejo, D., & Ollero, A. (2011). Path planning method based on Genetic Algorithms and the Monte-Carlo method to avoid aerial vehicle collisions under uncertainties. In Proceedings of the IEEE International Conference on Robotics and Automation (pp. 4429–4434). https://doi.org/10.1109/ICRA.2011.5980246

Colyvan, M., Justus, J., & Regan, H. M. (2011). The conservation game. Biological Conservation, 144(4), 1246–1253. http://doi.org/10.1016/j.biocon.2010.10.028

Duffy, R., St John, F. A. V, Büscher, B., & Brockington, D. (2016). Toward a new understanding of the links between poverty and illegal wildlife hunting. Conservation Biology, 30(1), 14–22. https://doi.org/10.1111/cobi.12622

Elston, D. A., Spezia, L., Baines, D., & Redpath, S. M. (2014). Working with stakeholders to reduce conflict-modelling the impact of varying hen harrier Circus cyaneus densities on red grouse Lagopus lagopus populations. Journal of Applied Ecology, 51(5), 1236–1245. http://doi.org/10.1111/1365-2664.12315

Farmer, J. D., & Foley, D. (2009). The economy needs agent-based modelling. Nature, 460(August), 685--686. https://doi.org/10.1038/460685a

Franco, C., Hepburn, L. A., Smith, D. J., Nimrod, S., & Tucker, A. (2016). A Bayesian Belief Network to assess rate of changes in coral reef ecosystems. Environmental Modelling and Software, 80, 132–142. https://doi.org/10.1016/j.envsoft.2016.02.029

Hake, M., Mansson, J., & Wiberg, A. (2010). A working model for preventing crop damage caused by increasing goose populations in Sweden. Ornis Svecica, 20(3-4), 225–233.

Hamblin, S. (2013). On the practical usage of genetic algorithms in ecology and evolution. Methods in Ecology and Evolution, 4(2), 184–194. https://doi.org/10.1111/2041-210X.12000

Heinonen, J. P. M., Palmer, S. C. F., Redpath, S. M., & Travis, J. M. J. (2014). Modelling hen harrier dynamics to inform human-wildlife conflict resolution: A spatially-realistic, individual-based approach. PLoS ONE, 9(11). http://doi.org/10.1371/journal.pone.0112492

Hindar, K., Fleming, I. A., McGinnity, P., & Diserud, O. (2006). Genetic and ecological effects of salmon farming on wild salmon: modelling from experimental results. ICES Journal of Marine Science, 63(7), 1234–1247. https://doi.org/10.1016/j.icesjms.2006.04.025

Janssen, M. A., Holahan, R., Lee, A., & Ostrom, E. (2010). Lab experiments for the study of socio-ecological systems. Science, 328, 613–618. http://doi.org/10.1126/science.1229223

Karlsson, S., Diserud, O. H., Fiske, P., & Hindar, K. (2016). Widespread genetic introgression of escaped farmed Atlantic salmon in wild salmon populations. ICES Journal of Marine Science, 0, fsw121. https://doi.org/10.1093/icesjms/fsw121

Liu, Y., Diserud, O. H., Hindar, K., & Skonhoft, A. (2013). An ecological-economic model on the effects of interactions between escaped farmed and wild salmon (Salmo salar). Fish and Fisheries, 14(2), 158–173. http://doi.org/10.1111/j.1467-2979.2012.00457.x

Luo, X., Yang, W., Kwong, C., Tang, J., & Tang, J. (2014). Linear programming embedded genetic algorithm for product family design optimization with maximizing imprecise part-worth utility function. Concurrent Engineering, 22(4), 309–319. https://doi.org/10.1177/1063293X14553068

Man, M., Zhang, Y., Ma, G., Friston, K., & Liu, S. (2016). Quantification of degeneracy in Hodgkin-Huxley neurons on Newman-Watts small world network. Journal of Theoretical Biology, 402, 62–74. http://doi.org/10.1016/j.jtbi.2016.05.004

Manfredo, M. J., Bruskotter, J. T., Teel, T. L., Fulton, D., Schwartz, S. H., Arlinghaus, R., ... Sullivan, L. (2016). Why social values cannot be changed for the sake of conservation. Conservation Biology. Accepted. https://doi.org/10.1111/cobi.12855.This

Mansson, J., Nilsson, L., & Hake, M. (2013). Territory size and habitat selection of breeding Common Cranes (Grus grus) in a boreal landscape. Ornis Fennica, 90(2), 65–72.

Marks, R. E. (1992). Breeding hybrid strategies: optimal behaviour for oligopolists. Journal of Evolutionary Economics, 2(1), 17–38. https://doi.org/10.1007/BF01196459

McAvoy, A., & Hauert, C. (2015). Asymmetric evolutionary games. PLoS Computational Biology, 11(8), e1004349. https://doi.org/10.1371/journal.pcbi.1004349

Mccann, R. K., Marcot, B. G., & Ellis, R. (2006). Bayesian belief networks: applications in ecology and natural resource. Canadian Journal of Forest Research, 36, 3053–3062.

Nellemann, C., Jordhoy, P., Stoen, O. G., & Strand, O. (2000). Cumulative impacts of tourist resorts on wild reindeer (Rangifer tarandus tarandus) during winter. Arctic, 53(1), 9–17. https://doi.org/10.14430/arctic829

Nellemann, C., Vistnes, I., Jordhoy, P., Strand, O., & Newton, A. (2003). Progressive impact of piecemeal infrastructure development on wild reindeer. Biological Conservation, 113(2), 307–317. https://doi.org/10.1016/S0006-3207(03)00048-X

Olaussen, J. O., & Skonhoft, A. (2008). On the economics of biological invasion: An application to recreational fishing. Natural Resource Modeling, 21(4), 625–653. https://doi.org/10.1111/j.1939-7445.2008.00026.x

Phan, D. (2003). From agent-based computational economics toward cognitive economics. In P. Bourgine & J.-P. Nadal (Eds.), Cognitive Economics: An Interdisciplinary Approach (pp. 369–396). London: Springer. https://doi.org/10.1016/j.joep.2004.12.002

Rumpff, L., Duncan, D. H., Vesk, P. A., Keith, D. A., & Wintle, B. A. (2011). State-and-transition modelling for Adaptive Management of native woodlands. Biological Conservation, 144(4), 1244–1235. http://doi.org/10.1016/j.biocon.2010.10.026

Strand, O., Nilsen, E. B., Solberg, E. J., & Linnell, J. C. D. (2012). Can management regulate the population size of wild reindeer (*Rangifer tarandus*) through harvest? Canadian Journal of Zoology, 90, 163–171. http://doi.org/Doi 10.1139/Z11-123

Tilman, A. R., Watson, J. R., & Levin, S. (2016). Maintaining cooperation in social-ecological systems: Theoretical Ecology. https://doi.org/10.1007/s12080-016-0318-8

Tu, M. T., Wolff, E., & Lamersdorf, W. (2000). Genetic algorithms for automated negotiations: a FSM-based application approach. Proceedings 11th International Workshop on Database and Expert Systems Applications, 1029–1033. https://doi.org/10.1109/DEXA.2000.875153

Wam, H. K., Bunnefeld, N., Clarke, N., & Hofstad, O. (2016). Conflicting interests of ecosystem services: Multi-criteria modelling and indirect evaluation to trade off monetary and non-monetary measures. Ecosystem Services.

Wang, P., Poe, G. L., & Wolf, S. A. (2017). Payments for ecosystem services and wealth distribution. Ecological Economics, 132, 63–68. https://doi.org/10.1016/j.ecolecon.2016.10.009

Whitacre, J. M. (2010). Degeneracy: a link between evolvability, robustness and complexity in biological systems. Theoretical Biology and Medical Modelling, 7, 6. https://doi.org/10.1186/1742-4682-7-6

Wright, G. D., Andersson, K. P., Gibson, C. C., & Evans, T. P. (2016). Decentralization can help reduce deforestation when user groups engage with local government. Proceedings of the National Academy of Sciences, 201610650. https://doi.org/10.1073/pnas.1610650114


<a name="cited">References cited</a>
-----------------------------------------
